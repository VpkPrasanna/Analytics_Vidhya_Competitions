{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "janta-Hack-CV",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-zQ1H7vw4f-",
        "colab_type": "code",
        "outputId": "0646d06a-d3f3-4801-d799-46209afdd5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ih7BshQwwF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKpW3qBMwwGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/Machine _Hack/janta-hack-CV/train/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqP3Y6TowwGf",
        "colab_type": "code",
        "outputId": "cc913443-c8b5-4c06-9e6b-7de7721e4d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_names</th>\n",
              "      <th>emergency_or_not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1503.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1420.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1764.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1356.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1117.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_names  emergency_or_not\n",
              "0    1503.jpg                 0\n",
              "1    1420.jpg                 0\n",
              "2    1764.jpg                 0\n",
              "3    1356.jpg                 0\n",
              "4    1117.jpg                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrtsPcmqwwG5",
        "colab_type": "code",
        "outputId": "65bb5de1-47be-4814-dccb-def220baac54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img(\"/content/drive/My Drive/Machine _Hack/janta-hack-CV/train/images/\"+train['image_names'][i], grayscale=False)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1646/1646 [00:04<00:00, 383.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j43cjeN8wwHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=train['emergency_or_not'].values\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKsvYAo6wwHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state = 294)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAEedxdbsgR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "81a50a29-38b2-4b50-db63-41ea4b8d8746"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "image_size = 224\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
        "    \n",
        "for layer in pre_trained_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in pre_trained_model.layers[15:]:\n",
        "    layer.trainable = True\n",
        "    \n",
        "last_layer = pre_trained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "    \n",
        "# Flatten the output layer to 1 dimension\n",
        "x = GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_7 (Glob (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 14,978,370\n",
            "Trainable params: 7,343,106\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVBxL9ln2_VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1hBGSKXtf0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e043ec0c-a834-4508-a5bf-fd800930bb66"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=50,  validation_data=(X_test, y_test),callbacks=[es,mc])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1399 samples, validate on 247 samples\n",
            "Epoch 1/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.2795 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.90688, saving model to best_model.h5\n",
            "Epoch 2/50\n",
            "1399/1399 [==============================] - 10s 7ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.2834 - val_accuracy: 0.9049\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.90688\n",
            "Epoch 3/50\n",
            "1399/1399 [==============================] - 10s 7ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.2900 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.90688 to 0.91093, saving model to best_model.h5\n",
            "Epoch 4/50\n",
            "1399/1399 [==============================] - 10s 7ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.2828 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91093\n",
            "Epoch 5/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.2838 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91093\n",
            "Epoch 6/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.2830 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91093\n",
            "Epoch 7/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.2868 - val_accuracy: 0.9049\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91093\n",
            "Epoch 8/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.2933 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91093\n",
            "Epoch 9/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.2954 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91093\n",
            "Epoch 10/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.2866 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91093\n",
            "Epoch 11/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.3019 - val_accuracy: 0.9130\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91093 to 0.91296, saving model to best_model.h5\n",
            "Epoch 12/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.3018 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91296\n",
            "Epoch 13/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.2960 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91296\n",
            "Epoch 14/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.2941 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91296\n",
            "Epoch 15/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.2881 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91296\n",
            "Epoch 16/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.2951 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91296\n",
            "Epoch 17/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.2861 - val_accuracy: 0.9049\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91296\n",
            "Epoch 18/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.3160 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91296\n",
            "Epoch 19/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.2892 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91296\n",
            "Epoch 20/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.2866 - val_accuracy: 0.9049\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91296\n",
            "Epoch 21/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.2916 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91296\n",
            "Epoch 22/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.2925 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91296\n",
            "Epoch 23/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.2908 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91296\n",
            "Epoch 24/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.2877 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91296\n",
            "Epoch 25/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.3118 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91296\n",
            "Epoch 26/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.2911 - val_accuracy: 0.9028\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91296\n",
            "Epoch 27/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.2902 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91296\n",
            "Epoch 28/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.2964 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91296\n",
            "Epoch 29/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.2997 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91296\n",
            "Epoch 30/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.2919 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91296\n",
            "Epoch 31/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.2950 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91296\n",
            "Epoch 32/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.3013 - val_accuracy: 0.9130\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91296\n",
            "Epoch 33/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.2951 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91296\n",
            "Epoch 34/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.3019 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91296\n",
            "Epoch 35/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.2991 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91296\n",
            "Epoch 36/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3068 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91296\n",
            "Epoch 37/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.2968 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91296\n",
            "Epoch 38/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.2987 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91296\n",
            "Epoch 39/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.2967 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91296\n",
            "Epoch 40/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.2974 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91296\n",
            "Epoch 41/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.2978 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91296\n",
            "Epoch 42/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.3040 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91296\n",
            "Epoch 43/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.2995 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91296\n",
            "Epoch 44/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.3009 - val_accuracy: 0.9049\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91296\n",
            "Epoch 45/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.3012 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91296\n",
            "Epoch 46/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.3032 - val_accuracy: 0.9109\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91296\n",
            "Epoch 47/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.2994 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91296\n",
            "Epoch 48/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.3024 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91296\n",
            "Epoch 49/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.2976 - val_accuracy: 0.9008\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91296\n",
            "Epoch 50/50\n",
            "1399/1399 [==============================] - 9s 7ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.2976 - val_accuracy: 0.9008\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8b0938bcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuTRLk0HwwHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',input_shape=(28,28,1)))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_uniform'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSSVfs3cwwHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(loss='binary_crossentropy',optimizer=\"sgd\",metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw6eqZiIwwHs",
        "colab_type": "code",
        "outputId": "d4a8ca1c-4a61-46c7-82f6-66d61e6d1c34",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train, y_train, epochs=500,  validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1399 samples, validate on 247 samples\n",
            "Epoch 1/500\n",
            "1399/1399 [==============================] - 8s 5ms/step - loss: 0.7981 - accuracy: 0.5611 - val_loss: 0.6766 - val_accuracy: 0.6235\n",
            "Epoch 2/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6777 - accuracy: 0.5890 - val_loss: 0.6571 - val_accuracy: 0.6680\n",
            "Epoch 3/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6658 - accuracy: 0.5854 - val_loss: 0.6462 - val_accuracy: 0.6518\n",
            "Epoch 4/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6589 - accuracy: 0.6133 - val_loss: 0.6273 - val_accuracy: 0.6842\n",
            "Epoch 5/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6599 - accuracy: 0.6097 - val_loss: 0.6206 - val_accuracy: 0.6518\n",
            "Epoch 6/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6253 - accuracy: 0.6505 - val_loss: 0.6421 - val_accuracy: 0.6397\n",
            "Epoch 7/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6186 - accuracy: 0.6497 - val_loss: 0.5962 - val_accuracy: 0.7328\n",
            "Epoch 8/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6096 - accuracy: 0.6762 - val_loss: 0.5742 - val_accuracy: 0.7247\n",
            "Epoch 9/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.6043 - accuracy: 0.6826 - val_loss: 0.5674 - val_accuracy: 0.7247\n",
            "Epoch 10/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5908 - accuracy: 0.6869 - val_loss: 0.5499 - val_accuracy: 0.7328\n",
            "Epoch 11/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5629 - accuracy: 0.7148 - val_loss: 0.5679 - val_accuracy: 0.7206\n",
            "Epoch 12/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5762 - accuracy: 0.6991 - val_loss: 0.5443 - val_accuracy: 0.7368\n",
            "Epoch 13/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5573 - accuracy: 0.7112 - val_loss: 0.5321 - val_accuracy: 0.7449\n",
            "Epoch 14/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5468 - accuracy: 0.7284 - val_loss: 0.5200 - val_accuracy: 0.7652\n",
            "Epoch 15/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5405 - accuracy: 0.7234 - val_loss: 0.5344 - val_accuracy: 0.7368\n",
            "Epoch 16/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5311 - accuracy: 0.7341 - val_loss: 0.5112 - val_accuracy: 0.7449\n",
            "Epoch 17/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5259 - accuracy: 0.7370 - val_loss: 0.5109 - val_accuracy: 0.7530\n",
            "Epoch 18/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5175 - accuracy: 0.7462 - val_loss: 0.5219 - val_accuracy: 0.7449\n",
            "Epoch 19/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5157 - accuracy: 0.7384 - val_loss: 0.5075 - val_accuracy: 0.7692\n",
            "Epoch 20/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5135 - accuracy: 0.7434 - val_loss: 0.5210 - val_accuracy: 0.7490\n",
            "Epoch 21/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.5187 - accuracy: 0.7377 - val_loss: 0.5174 - val_accuracy: 0.7490\n",
            "Epoch 22/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4998 - accuracy: 0.7570 - val_loss: 0.5063 - val_accuracy: 0.7652\n",
            "Epoch 23/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4893 - accuracy: 0.7698 - val_loss: 0.4963 - val_accuracy: 0.7895\n",
            "Epoch 24/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4961 - accuracy: 0.7534 - val_loss: 0.4982 - val_accuracy: 0.7692\n",
            "Epoch 25/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4958 - accuracy: 0.7541 - val_loss: 0.4942 - val_accuracy: 0.7733\n",
            "Epoch 26/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4815 - accuracy: 0.7655 - val_loss: 0.4889 - val_accuracy: 0.7814\n",
            "Epoch 27/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4736 - accuracy: 0.7770 - val_loss: 0.4841 - val_accuracy: 0.7773\n",
            "Epoch 28/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4821 - accuracy: 0.7684 - val_loss: 0.4834 - val_accuracy: 0.7773\n",
            "Epoch 29/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4766 - accuracy: 0.7763 - val_loss: 0.4800 - val_accuracy: 0.7895\n",
            "Epoch 30/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4741 - accuracy: 0.7670 - val_loss: 0.4856 - val_accuracy: 0.7733\n",
            "Epoch 31/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4676 - accuracy: 0.7777 - val_loss: 0.5351 - val_accuracy: 0.7206\n",
            "Epoch 32/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4526 - accuracy: 0.7891 - val_loss: 0.4782 - val_accuracy: 0.7935\n",
            "Epoch 33/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4575 - accuracy: 0.7877 - val_loss: 0.4873 - val_accuracy: 0.7773\n",
            "Epoch 34/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.4598 - accuracy: 0.7798 - val_loss: 0.4732 - val_accuracy: 0.7814\n",
            "Epoch 35/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4569 - accuracy: 0.7941 - val_loss: 0.4803 - val_accuracy: 0.7652\n",
            "Epoch 36/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4547 - accuracy: 0.7898 - val_loss: 0.4856 - val_accuracy: 0.7692\n",
            "Epoch 37/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4358 - accuracy: 0.7920 - val_loss: 0.5085 - val_accuracy: 0.7449\n",
            "Epoch 38/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4271 - accuracy: 0.8099 - val_loss: 0.4920 - val_accuracy: 0.7611\n",
            "Epoch 39/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4227 - accuracy: 0.7999 - val_loss: 0.4716 - val_accuracy: 0.7814\n",
            "Epoch 40/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4345 - accuracy: 0.7970 - val_loss: 0.4823 - val_accuracy: 0.7854\n",
            "Epoch 41/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.4201 - accuracy: 0.8120 - val_loss: 0.4703 - val_accuracy: 0.7773\n",
            "Epoch 42/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.4224 - accuracy: 0.8113 - val_loss: 0.4670 - val_accuracy: 0.7935\n",
            "Epoch 43/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.4260 - accuracy: 0.8041 - val_loss: 0.5207 - val_accuracy: 0.7449\n",
            "Epoch 44/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.4126 - accuracy: 0.8142 - val_loss: 0.4765 - val_accuracy: 0.7652\n",
            "Epoch 45/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.3941 - accuracy: 0.8277 - val_loss: 0.4687 - val_accuracy: 0.8138\n",
            "Epoch 46/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.4145 - accuracy: 0.8127 - val_loss: 0.4969 - val_accuracy: 0.7692\n",
            "Epoch 47/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3943 - accuracy: 0.8306 - val_loss: 0.5055 - val_accuracy: 0.7611\n",
            "Epoch 48/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3966 - accuracy: 0.8142 - val_loss: 0.4651 - val_accuracy: 0.7692\n",
            "Epoch 49/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3965 - accuracy: 0.8170 - val_loss: 0.4560 - val_accuracy: 0.7854\n",
            "Epoch 50/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3821 - accuracy: 0.8234 - val_loss: 0.4570 - val_accuracy: 0.7935\n",
            "Epoch 51/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3788 - accuracy: 0.8263 - val_loss: 0.4634 - val_accuracy: 0.7692\n",
            "Epoch 52/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3755 - accuracy: 0.8277 - val_loss: 0.4642 - val_accuracy: 0.7773\n",
            "Epoch 53/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3747 - accuracy: 0.8292 - val_loss: 0.4861 - val_accuracy: 0.7571\n",
            "Epoch 54/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3592 - accuracy: 0.8399 - val_loss: 0.4544 - val_accuracy: 0.7895\n",
            "Epoch 55/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3546 - accuracy: 0.8349 - val_loss: 0.4545 - val_accuracy: 0.7935\n",
            "Epoch 56/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3684 - accuracy: 0.8356 - val_loss: 0.4512 - val_accuracy: 0.8057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 57/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3528 - accuracy: 0.8463 - val_loss: 0.4647 - val_accuracy: 0.8016\n",
            "Epoch 58/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3497 - accuracy: 0.8513 - val_loss: 0.4484 - val_accuracy: 0.8057\n",
            "Epoch 59/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3525 - accuracy: 0.8413 - val_loss: 0.4872 - val_accuracy: 0.7935\n",
            "Epoch 60/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3468 - accuracy: 0.8528 - val_loss: 0.4859 - val_accuracy: 0.7773\n",
            "Epoch 61/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3344 - accuracy: 0.8549 - val_loss: 0.4635 - val_accuracy: 0.7733\n",
            "Epoch 62/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3242 - accuracy: 0.8628 - val_loss: 0.4517 - val_accuracy: 0.7814\n",
            "Epoch 63/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3298 - accuracy: 0.8599 - val_loss: 0.4666 - val_accuracy: 0.7773\n",
            "Epoch 64/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3290 - accuracy: 0.8613 - val_loss: 0.4620 - val_accuracy: 0.8178\n",
            "Epoch 65/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3307 - accuracy: 0.8620 - val_loss: 0.4532 - val_accuracy: 0.7976\n",
            "Epoch 66/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3101 - accuracy: 0.8663 - val_loss: 0.4460 - val_accuracy: 0.7935\n",
            "Epoch 67/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3083 - accuracy: 0.8620 - val_loss: 0.4643 - val_accuracy: 0.8097\n",
            "Epoch 68/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3102 - accuracy: 0.8620 - val_loss: 0.4551 - val_accuracy: 0.8057\n",
            "Epoch 69/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.3101 - accuracy: 0.8635 - val_loss: 0.4529 - val_accuracy: 0.8097\n",
            "Epoch 70/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2883 - accuracy: 0.8721 - val_loss: 0.4909 - val_accuracy: 0.7814\n",
            "Epoch 71/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2841 - accuracy: 0.8699 - val_loss: 0.4586 - val_accuracy: 0.7733\n",
            "Epoch 72/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2799 - accuracy: 0.8806 - val_loss: 0.4701 - val_accuracy: 0.7895\n",
            "Epoch 73/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2944 - accuracy: 0.8706 - val_loss: 0.4529 - val_accuracy: 0.7895\n",
            "Epoch 74/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2845 - accuracy: 0.8771 - val_loss: 0.4633 - val_accuracy: 0.7976\n",
            "Epoch 75/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2784 - accuracy: 0.8813 - val_loss: 0.4993 - val_accuracy: 0.7814\n",
            "Epoch 76/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2699 - accuracy: 0.8856 - val_loss: 0.4463 - val_accuracy: 0.8057\n",
            "Epoch 77/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2648 - accuracy: 0.8813 - val_loss: 0.5016 - val_accuracy: 0.7814\n",
            "Epoch 78/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2628 - accuracy: 0.8856 - val_loss: 0.4616 - val_accuracy: 0.7733\n",
            "Epoch 79/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2473 - accuracy: 0.9014 - val_loss: 0.4551 - val_accuracy: 0.8097\n",
            "Epoch 80/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2516 - accuracy: 0.8928 - val_loss: 0.4794 - val_accuracy: 0.7976\n",
            "Epoch 81/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2586 - accuracy: 0.8921 - val_loss: 0.4546 - val_accuracy: 0.7976\n",
            "Epoch 82/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2392 - accuracy: 0.9014 - val_loss: 0.4546 - val_accuracy: 0.8016\n",
            "Epoch 83/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2286 - accuracy: 0.9049 - val_loss: 0.4680 - val_accuracy: 0.7935\n",
            "Epoch 84/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2302 - accuracy: 0.9092 - val_loss: 0.4667 - val_accuracy: 0.7895\n",
            "Epoch 85/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2294 - accuracy: 0.9078 - val_loss: 0.4582 - val_accuracy: 0.8016\n",
            "Epoch 86/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2245 - accuracy: 0.9128 - val_loss: 0.4631 - val_accuracy: 0.8016\n",
            "Epoch 87/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2345 - accuracy: 0.9049 - val_loss: 0.4632 - val_accuracy: 0.8138\n",
            "Epoch 88/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2113 - accuracy: 0.9207 - val_loss: 0.4562 - val_accuracy: 0.7976\n",
            "Epoch 89/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2240 - accuracy: 0.9021 - val_loss: 0.4896 - val_accuracy: 0.8219\n",
            "Epoch 90/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1985 - accuracy: 0.9264 - val_loss: 0.4637 - val_accuracy: 0.8016\n",
            "Epoch 91/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2086 - accuracy: 0.9107 - val_loss: 0.4633 - val_accuracy: 0.8016\n",
            "Epoch 92/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2158 - accuracy: 0.9114 - val_loss: 0.4637 - val_accuracy: 0.8097\n",
            "Epoch 93/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.2096 - accuracy: 0.9178 - val_loss: 0.4597 - val_accuracy: 0.7895\n",
            "Epoch 94/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.1947 - accuracy: 0.9278 - val_loss: 0.4722 - val_accuracy: 0.8057\n",
            "Epoch 95/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1957 - accuracy: 0.9135 - val_loss: 0.4836 - val_accuracy: 0.8138\n",
            "Epoch 96/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1989 - accuracy: 0.9235 - val_loss: 0.5014 - val_accuracy: 0.7976\n",
            "Epoch 97/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1796 - accuracy: 0.9271 - val_loss: 0.4834 - val_accuracy: 0.8016\n",
            "Epoch 98/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1945 - accuracy: 0.9185 - val_loss: 0.4710 - val_accuracy: 0.8097\n",
            "Epoch 99/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1819 - accuracy: 0.9264 - val_loss: 0.4710 - val_accuracy: 0.7976\n",
            "Epoch 100/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1807 - accuracy: 0.9264 - val_loss: 0.4699 - val_accuracy: 0.7935\n",
            "Epoch 101/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1789 - accuracy: 0.9242 - val_loss: 0.4705 - val_accuracy: 0.8178\n",
            "Epoch 102/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1855 - accuracy: 0.9242 - val_loss: 0.4717 - val_accuracy: 0.8016\n",
            "Epoch 103/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1625 - accuracy: 0.9407 - val_loss: 0.5002 - val_accuracy: 0.8057\n",
            "Epoch 104/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1617 - accuracy: 0.9314 - val_loss: 0.4946 - val_accuracy: 0.8138\n",
            "Epoch 105/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1664 - accuracy: 0.9385 - val_loss: 0.4975 - val_accuracy: 0.8097\n",
            "Epoch 106/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1609 - accuracy: 0.9450 - val_loss: 0.5239 - val_accuracy: 0.8138\n",
            "Epoch 107/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1640 - accuracy: 0.9378 - val_loss: 0.4834 - val_accuracy: 0.8097\n",
            "Epoch 108/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1445 - accuracy: 0.9485 - val_loss: 0.4881 - val_accuracy: 0.8057\n",
            "Epoch 109/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1432 - accuracy: 0.9507 - val_loss: 0.4869 - val_accuracy: 0.8097\n",
            "Epoch 110/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1492 - accuracy: 0.9442 - val_loss: 0.4817 - val_accuracy: 0.8016\n",
            "Epoch 111/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1498 - accuracy: 0.9485 - val_loss: 0.4844 - val_accuracy: 0.8219\n",
            "Epoch 112/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1472 - accuracy: 0.9435 - val_loss: 0.5169 - val_accuracy: 0.8138\n",
            "Epoch 113/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.1435 - accuracy: 0.9550 - val_loss: 0.4937 - val_accuracy: 0.8097\n",
            "Epoch 114/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.1311 - accuracy: 0.9514 - val_loss: 0.5248 - val_accuracy: 0.8016\n",
            "Epoch 115/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.1353 - accuracy: 0.9464 - val_loss: 0.5044 - val_accuracy: 0.8057\n",
            "Epoch 116/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.1287 - accuracy: 0.9543 - val_loss: 0.5196 - val_accuracy: 0.7935\n",
            "Epoch 117/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.1480 - accuracy: 0.9392 - val_loss: 0.4909 - val_accuracy: 0.7976\n",
            "Epoch 118/500\n",
            "1399/1399 [==============================] - 6s 4ms/step - loss: 0.1286 - accuracy: 0.9521 - val_loss: 0.4962 - val_accuracy: 0.7935\n",
            "Epoch 119/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.1363 - accuracy: 0.9457 - val_loss: 0.4962 - val_accuracy: 0.8057\n",
            "Epoch 120/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.1266 - accuracy: 0.9578 - val_loss: 0.5058 - val_accuracy: 0.8057\n",
            "Epoch 121/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.1100 - accuracy: 0.9564 - val_loss: 0.5211 - val_accuracy: 0.8097\n",
            "Epoch 122/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1164 - accuracy: 0.9535 - val_loss: 0.7460 - val_accuracy: 0.7328\n",
            "Epoch 123/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1105 - accuracy: 0.9700 - val_loss: 0.5177 - val_accuracy: 0.8097\n",
            "Epoch 124/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1038 - accuracy: 0.9607 - val_loss: 0.5405 - val_accuracy: 0.8138\n",
            "Epoch 125/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1211 - accuracy: 0.9543 - val_loss: 0.5238 - val_accuracy: 0.8016\n",
            "Epoch 126/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1096 - accuracy: 0.9635 - val_loss: 0.5074 - val_accuracy: 0.8138\n",
            "Epoch 127/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1167 - accuracy: 0.9571 - val_loss: 0.5068 - val_accuracy: 0.8097\n",
            "Epoch 128/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0982 - accuracy: 0.9650 - val_loss: 0.5725 - val_accuracy: 0.8016\n",
            "Epoch 129/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1069 - accuracy: 0.9635 - val_loss: 0.5210 - val_accuracy: 0.8016\n",
            "Epoch 130/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1036 - accuracy: 0.9657 - val_loss: 0.5455 - val_accuracy: 0.8057\n",
            "Epoch 131/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1033 - accuracy: 0.9614 - val_loss: 0.5506 - val_accuracy: 0.8097\n",
            "Epoch 132/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1058 - accuracy: 0.9600 - val_loss: 0.5237 - val_accuracy: 0.8138\n",
            "Epoch 133/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.1062 - accuracy: 0.9664 - val_loss: 0.5323 - val_accuracy: 0.8016\n",
            "Epoch 134/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.0919 - accuracy: 0.9714 - val_loss: 0.5249 - val_accuracy: 0.8097\n",
            "Epoch 135/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.0944 - accuracy: 0.9650 - val_loss: 0.5215 - val_accuracy: 0.8138\n",
            "Epoch 136/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.0957 - accuracy: 0.9657 - val_loss: 0.5113 - val_accuracy: 0.8178\n",
            "Epoch 137/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0982 - accuracy: 0.9621 - val_loss: 0.5453 - val_accuracy: 0.8016\n",
            "Epoch 138/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0876 - accuracy: 0.9700 - val_loss: 0.5321 - val_accuracy: 0.8057\n",
            "Epoch 139/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.0899 - accuracy: 0.9693 - val_loss: 0.5429 - val_accuracy: 0.8016\n",
            "Epoch 140/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0896 - accuracy: 0.9693 - val_loss: 0.5663 - val_accuracy: 0.7976\n",
            "Epoch 141/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0872 - accuracy: 0.9736 - val_loss: 0.5691 - val_accuracy: 0.8097\n",
            "Epoch 142/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0881 - accuracy: 0.9657 - val_loss: 0.5497 - val_accuracy: 0.8057\n",
            "Epoch 143/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.0805 - accuracy: 0.9736 - val_loss: 0.5555 - val_accuracy: 0.8097\n",
            "Epoch 144/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.0808 - accuracy: 0.9793 - val_loss: 0.5423 - val_accuracy: 0.8057\n",
            "Epoch 145/500\n",
            "1399/1399 [==============================] - 6s 4ms/step - loss: 0.0947 - accuracy: 0.9650 - val_loss: 0.5657 - val_accuracy: 0.8057\n",
            "Epoch 146/500\n",
            "1399/1399 [==============================] - 5s 3ms/step - loss: 0.0730 - accuracy: 0.9771 - val_loss: 0.5454 - val_accuracy: 0.7976\n",
            "Epoch 147/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0723 - accuracy: 0.9757 - val_loss: 0.5681 - val_accuracy: 0.7935\n",
            "Epoch 148/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.0823 - accuracy: 0.9707 - val_loss: 0.5863 - val_accuracy: 0.8016\n",
            "Epoch 149/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0770 - accuracy: 0.9721 - val_loss: 0.6142 - val_accuracy: 0.8016\n",
            "Epoch 150/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0802 - accuracy: 0.9721 - val_loss: 0.5689 - val_accuracy: 0.8097\n",
            "Epoch 151/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0775 - accuracy: 0.9764 - val_loss: 0.6007 - val_accuracy: 0.8016\n",
            "Epoch 152/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0753 - accuracy: 0.9700 - val_loss: 0.5999 - val_accuracy: 0.7935\n",
            "Epoch 153/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0706 - accuracy: 0.9771 - val_loss: 0.5807 - val_accuracy: 0.8057\n",
            "Epoch 154/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0717 - accuracy: 0.9764 - val_loss: 0.6019 - val_accuracy: 0.7935\n",
            "Epoch 155/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0718 - accuracy: 0.9814 - val_loss: 0.5866 - val_accuracy: 0.7935\n",
            "Epoch 156/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0813 - accuracy: 0.9707 - val_loss: 0.5526 - val_accuracy: 0.7976\n",
            "Epoch 157/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.5916 - val_accuracy: 0.7976\n",
            "Epoch 158/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0572 - accuracy: 0.9843 - val_loss: 0.6023 - val_accuracy: 0.8138\n",
            "Epoch 159/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0694 - accuracy: 0.9771 - val_loss: 0.6149 - val_accuracy: 0.7976\n",
            "Epoch 160/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 0.5991 - val_accuracy: 0.8097\n",
            "Epoch 161/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0641 - accuracy: 0.9786 - val_loss: 0.6160 - val_accuracy: 0.8016\n",
            "Epoch 162/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0650 - accuracy: 0.9814 - val_loss: 0.5741 - val_accuracy: 0.8097\n",
            "Epoch 163/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0547 - accuracy: 0.9857 - val_loss: 0.5860 - val_accuracy: 0.8057\n",
            "Epoch 164/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0603 - accuracy: 0.9793 - val_loss: 0.6586 - val_accuracy: 0.8097\n",
            "Epoch 165/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0754 - accuracy: 0.9728 - val_loss: 0.5781 - val_accuracy: 0.8057\n",
            "Epoch 166/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0590 - accuracy: 0.9807 - val_loss: 0.6099 - val_accuracy: 0.8138\n",
            "Epoch 167/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.5977 - val_accuracy: 0.8097\n",
            "Epoch 168/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0582 - accuracy: 0.9836 - val_loss: 0.6205 - val_accuracy: 0.8057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 169/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0577 - accuracy: 0.9828 - val_loss: 0.6352 - val_accuracy: 0.7976\n",
            "Epoch 170/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0542 - accuracy: 0.9814 - val_loss: 0.6282 - val_accuracy: 0.8219\n",
            "Epoch 171/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0671 - accuracy: 0.9821 - val_loss: 0.6223 - val_accuracy: 0.7935\n",
            "Epoch 172/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0635 - accuracy: 0.9807 - val_loss: 0.6108 - val_accuracy: 0.8016\n",
            "Epoch 173/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0600 - accuracy: 0.9814 - val_loss: 0.6041 - val_accuracy: 0.8016\n",
            "Epoch 174/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0581 - accuracy: 0.9814 - val_loss: 0.6298 - val_accuracy: 0.7976\n",
            "Epoch 175/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0574 - accuracy: 0.9771 - val_loss: 0.5963 - val_accuracy: 0.8097\n",
            "Epoch 176/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0520 - accuracy: 0.9821 - val_loss: 0.6460 - val_accuracy: 0.7976\n",
            "Epoch 177/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0546 - accuracy: 0.9843 - val_loss: 0.5983 - val_accuracy: 0.8097\n",
            "Epoch 178/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0469 - accuracy: 0.9871 - val_loss: 0.6209 - val_accuracy: 0.8057\n",
            "Epoch 179/500\n",
            "1399/1399 [==============================] - 5s 4ms/step - loss: 0.0618 - accuracy: 0.9764 - val_loss: 0.6009 - val_accuracy: 0.8138\n",
            "Epoch 180/500\n",
            "1399/1399 [==============================] - 6s 4ms/step - loss: 0.0572 - accuracy: 0.9850 - val_loss: 0.6124 - val_accuracy: 0.8016\n",
            "Epoch 181/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0460 - accuracy: 0.9878 - val_loss: 0.6748 - val_accuracy: 0.8057\n",
            "Epoch 182/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0513 - accuracy: 0.9814 - val_loss: 0.6390 - val_accuracy: 0.7935\n",
            "Epoch 183/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.6709 - val_accuracy: 0.7935\n",
            "Epoch 184/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0473 - accuracy: 0.9878 - val_loss: 0.6397 - val_accuracy: 0.8097\n",
            "Epoch 185/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0554 - accuracy: 0.9814 - val_loss: 0.6239 - val_accuracy: 0.7976\n",
            "Epoch 186/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0483 - accuracy: 0.9864 - val_loss: 0.6142 - val_accuracy: 0.8057\n",
            "Epoch 187/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0451 - accuracy: 0.9857 - val_loss: 0.6161 - val_accuracy: 0.7976\n",
            "Epoch 188/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0531 - accuracy: 0.9793 - val_loss: 0.6719 - val_accuracy: 0.8057\n",
            "Epoch 189/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 0.6447 - val_accuracy: 0.8057\n",
            "Epoch 190/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0451 - accuracy: 0.9843 - val_loss: 0.6481 - val_accuracy: 0.7976\n",
            "Epoch 191/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0468 - accuracy: 0.9828 - val_loss: 0.6248 - val_accuracy: 0.7976\n",
            "Epoch 192/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.6392 - val_accuracy: 0.7895\n",
            "Epoch 193/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9836 - val_loss: 0.6270 - val_accuracy: 0.8016\n",
            "Epoch 194/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0424 - accuracy: 0.9886 - val_loss: 0.6549 - val_accuracy: 0.8057\n",
            "Epoch 195/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0432 - accuracy: 0.9871 - val_loss: 0.6684 - val_accuracy: 0.7976\n",
            "Epoch 196/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9886 - val_loss: 0.6642 - val_accuracy: 0.8057\n",
            "Epoch 197/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.6593 - val_accuracy: 0.8016\n",
            "Epoch 198/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 0.6417 - val_accuracy: 0.8057\n",
            "Epoch 199/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0456 - accuracy: 0.9843 - val_loss: 0.6404 - val_accuracy: 0.7976\n",
            "Epoch 200/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0453 - accuracy: 0.9836 - val_loss: 0.6485 - val_accuracy: 0.8057\n",
            "Epoch 201/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0376 - accuracy: 0.9914 - val_loss: 0.6686 - val_accuracy: 0.8138\n",
            "Epoch 202/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.6684 - val_accuracy: 0.8097\n",
            "Epoch 203/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0432 - accuracy: 0.9878 - val_loss: 0.6523 - val_accuracy: 0.8097\n",
            "Epoch 204/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9886 - val_loss: 0.6207 - val_accuracy: 0.8097\n",
            "Epoch 205/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.6729 - val_accuracy: 0.8016\n",
            "Epoch 206/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.7018 - val_accuracy: 0.8097\n",
            "Epoch 207/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.7049 - val_accuracy: 0.8097\n",
            "Epoch 208/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0335 - accuracy: 0.9921 - val_loss: 0.6809 - val_accuracy: 0.8097\n",
            "Epoch 209/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0335 - accuracy: 0.9943 - val_loss: 0.6758 - val_accuracy: 0.8016\n",
            "Epoch 210/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.7126 - val_accuracy: 0.8016\n",
            "Epoch 211/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 0.6536 - val_accuracy: 0.8097\n",
            "Epoch 212/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0294 - accuracy: 0.9929 - val_loss: 0.7047 - val_accuracy: 0.8138\n",
            "Epoch 213/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0356 - accuracy: 0.9871 - val_loss: 0.7292 - val_accuracy: 0.8097\n",
            "Epoch 214/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.6871 - val_accuracy: 0.8057\n",
            "Epoch 215/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.7105 - val_accuracy: 0.8057\n",
            "Epoch 216/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0308 - accuracy: 0.9921 - val_loss: 0.7381 - val_accuracy: 0.7976\n",
            "Epoch 217/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.6939 - val_accuracy: 0.8057\n",
            "Epoch 218/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0363 - accuracy: 0.9886 - val_loss: 0.6737 - val_accuracy: 0.8178\n",
            "Epoch 219/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.7049 - val_accuracy: 0.8057\n",
            "Epoch 220/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0289 - accuracy: 0.9929 - val_loss: 0.7049 - val_accuracy: 0.8097\n",
            "Epoch 221/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.7007 - val_accuracy: 0.7976\n",
            "Epoch 222/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0319 - accuracy: 0.9914 - val_loss: 0.6951 - val_accuracy: 0.8138\n",
            "Epoch 223/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0383 - accuracy: 0.9850 - val_loss: 0.6803 - val_accuracy: 0.8097\n",
            "Epoch 224/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0272 - accuracy: 0.9957 - val_loss: 0.7017 - val_accuracy: 0.8138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 225/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.7150 - val_accuracy: 0.8097\n",
            "Epoch 226/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0419 - accuracy: 0.9871 - val_loss: 0.7063 - val_accuracy: 0.8016\n",
            "Epoch 227/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0390 - accuracy: 0.9871 - val_loss: 0.7094 - val_accuracy: 0.8097\n",
            "Epoch 228/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0426 - accuracy: 0.9850 - val_loss: 0.6733 - val_accuracy: 0.8016\n",
            "Epoch 229/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 0.6851 - val_accuracy: 0.8057\n",
            "Epoch 230/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.7081 - val_accuracy: 0.8057\n",
            "Epoch 231/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9871 - val_loss: 0.7038 - val_accuracy: 0.7976\n",
            "Epoch 232/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0278 - accuracy: 0.9929 - val_loss: 0.7064 - val_accuracy: 0.8097\n",
            "Epoch 233/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0300 - accuracy: 0.9929 - val_loss: 0.6839 - val_accuracy: 0.8138\n",
            "Epoch 234/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.7093 - val_accuracy: 0.8097\n",
            "Epoch 235/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0377 - accuracy: 0.9907 - val_loss: 0.6939 - val_accuracy: 0.8097\n",
            "Epoch 236/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 0.6870 - val_accuracy: 0.8057\n",
            "Epoch 237/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0322 - accuracy: 0.9907 - val_loss: 0.8119 - val_accuracy: 0.8097\n",
            "Epoch 238/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0306 - accuracy: 0.9950 - val_loss: 0.7188 - val_accuracy: 0.8097\n",
            "Epoch 239/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9893 - val_loss: 0.6847 - val_accuracy: 0.8138\n",
            "Epoch 240/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.7142 - val_accuracy: 0.8178\n",
            "Epoch 241/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9864 - val_loss: 0.7268 - val_accuracy: 0.8178\n",
            "Epoch 242/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0379 - accuracy: 0.9871 - val_loss: 0.6921 - val_accuracy: 0.8057\n",
            "Epoch 243/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.6818 - val_accuracy: 0.8138\n",
            "Epoch 244/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.7019 - val_accuracy: 0.8138\n",
            "Epoch 245/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0260 - accuracy: 0.9943 - val_loss: 0.7285 - val_accuracy: 0.8138\n",
            "Epoch 246/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0372 - accuracy: 0.9850 - val_loss: 0.7170 - val_accuracy: 0.8057\n",
            "Epoch 247/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.7676 - val_accuracy: 0.7976\n",
            "Epoch 248/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 0.7336 - val_accuracy: 0.8016\n",
            "Epoch 249/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.7317 - val_accuracy: 0.8057\n",
            "Epoch 250/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.7522 - val_accuracy: 0.8097\n",
            "Epoch 251/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.7415 - val_accuracy: 0.7976\n",
            "Epoch 252/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0261 - accuracy: 0.9943 - val_loss: 0.7319 - val_accuracy: 0.8097\n",
            "Epoch 253/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.7450 - val_accuracy: 0.8057\n",
            "Epoch 254/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0301 - accuracy: 0.9921 - val_loss: 0.7284 - val_accuracy: 0.8178\n",
            "Epoch 255/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.7401 - val_accuracy: 0.8178\n",
            "Epoch 256/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9900 - val_loss: 0.7372 - val_accuracy: 0.8178\n",
            "Epoch 257/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9950 - val_loss: 0.7405 - val_accuracy: 0.8057\n",
            "Epoch 258/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.7952 - val_accuracy: 0.7976\n",
            "Epoch 259/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.7902 - val_accuracy: 0.7976\n",
            "Epoch 260/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0281 - accuracy: 0.9893 - val_loss: 0.7749 - val_accuracy: 0.8057\n",
            "Epoch 261/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.7668 - val_accuracy: 0.8219\n",
            "Epoch 262/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0256 - accuracy: 0.9907 - val_loss: 0.7681 - val_accuracy: 0.8219\n",
            "Epoch 263/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9907 - val_loss: 0.7883 - val_accuracy: 0.8097\n",
            "Epoch 264/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.7684 - val_accuracy: 0.8178\n",
            "Epoch 265/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0247 - accuracy: 0.9957 - val_loss: 0.7399 - val_accuracy: 0.8178\n",
            "Epoch 266/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.7362 - val_accuracy: 0.8219\n",
            "Epoch 267/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0169 - accuracy: 0.9986 - val_loss: 0.7480 - val_accuracy: 0.8219\n",
            "Epoch 268/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.8101 - val_accuracy: 0.8178\n",
            "Epoch 269/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.7849 - val_accuracy: 0.8219\n",
            "Epoch 270/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.7886 - val_accuracy: 0.8138\n",
            "Epoch 271/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0177 - accuracy: 0.9964 - val_loss: 0.7919 - val_accuracy: 0.8178\n",
            "Epoch 272/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.8086 - val_accuracy: 0.8097\n",
            "Epoch 273/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.8006 - val_accuracy: 0.8178\n",
            "Epoch 274/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.7955 - val_accuracy: 0.8138\n",
            "Epoch 275/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.7640 - val_accuracy: 0.8097\n",
            "Epoch 276/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.7696 - val_accuracy: 0.8097\n",
            "Epoch 277/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.7448 - val_accuracy: 0.8097\n",
            "Epoch 278/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.7468 - val_accuracy: 0.8138\n",
            "Epoch 279/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0273 - accuracy: 0.9929 - val_loss: 0.7463 - val_accuracy: 0.8138\n",
            "Epoch 280/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.7768 - val_accuracy: 0.8097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 281/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.7841 - val_accuracy: 0.8097\n",
            "Epoch 282/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.7752 - val_accuracy: 0.8057\n",
            "Epoch 283/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.7897 - val_accuracy: 0.8057\n",
            "Epoch 284/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.8193 - val_accuracy: 0.8097\n",
            "Epoch 285/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.8205 - val_accuracy: 0.8138\n",
            "Epoch 286/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0173 - accuracy: 0.9971 - val_loss: 0.8052 - val_accuracy: 0.8219\n",
            "Epoch 287/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.7588 - val_accuracy: 0.8138\n",
            "Epoch 288/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.7917 - val_accuracy: 0.8097\n",
            "Epoch 289/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.7675 - val_accuracy: 0.8097\n",
            "Epoch 290/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.7922 - val_accuracy: 0.8097\n",
            "Epoch 291/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.7813 - val_accuracy: 0.8097\n",
            "Epoch 292/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.7881 - val_accuracy: 0.8057\n",
            "Epoch 293/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.7756 - val_accuracy: 0.8138\n",
            "Epoch 294/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.7938 - val_accuracy: 0.8219\n",
            "Epoch 295/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.7867 - val_accuracy: 0.8097\n",
            "Epoch 296/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.7923 - val_accuracy: 0.8097\n",
            "Epoch 297/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9957 - val_loss: 0.7932 - val_accuracy: 0.8016\n",
            "Epoch 298/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9971 - val_loss: 0.7959 - val_accuracy: 0.8057\n",
            "Epoch 299/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.8093 - val_accuracy: 0.8097\n",
            "Epoch 300/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.8403 - val_accuracy: 0.8138\n",
            "Epoch 301/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.8001 - val_accuracy: 0.8097\n",
            "Epoch 302/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.7727 - val_accuracy: 0.8097\n",
            "Epoch 303/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.7845 - val_accuracy: 0.8016\n",
            "Epoch 304/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.8152 - val_accuracy: 0.8016\n",
            "Epoch 305/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0189 - accuracy: 0.9921 - val_loss: 0.8072 - val_accuracy: 0.8097\n",
            "Epoch 306/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0191 - accuracy: 0.9971 - val_loss: 0.8245 - val_accuracy: 0.8097\n",
            "Epoch 307/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.8525 - val_accuracy: 0.8057\n",
            "Epoch 308/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0271 - accuracy: 0.9886 - val_loss: 0.7980 - val_accuracy: 0.8057\n",
            "Epoch 309/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9914 - val_loss: 0.7618 - val_accuracy: 0.8097\n",
            "Epoch 310/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 0.7725 - val_accuracy: 0.8057\n",
            "Epoch 311/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 0.7638 - val_accuracy: 0.8138\n",
            "Epoch 312/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.7851 - val_accuracy: 0.8057\n",
            "Epoch 313/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.7900 - val_accuracy: 0.8097\n",
            "Epoch 314/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.7705 - val_accuracy: 0.8178\n",
            "Epoch 315/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.7812 - val_accuracy: 0.8057\n",
            "Epoch 316/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.8160 - val_accuracy: 0.8138\n",
            "Epoch 317/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.8200 - val_accuracy: 0.8057\n",
            "Epoch 318/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.8313 - val_accuracy: 0.8097\n",
            "Epoch 319/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.8061 - val_accuracy: 0.8057\n",
            "Epoch 320/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0115 - accuracy: 0.9986 - val_loss: 0.8395 - val_accuracy: 0.8057\n",
            "Epoch 321/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.8189 - val_accuracy: 0.8138\n",
            "Epoch 322/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.8144 - val_accuracy: 0.8057\n",
            "Epoch 323/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0200 - accuracy: 0.9907 - val_loss: 0.8238 - val_accuracy: 0.8097\n",
            "Epoch 324/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.7830 - val_accuracy: 0.8138\n",
            "Epoch 325/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.8002 - val_accuracy: 0.8097\n",
            "Epoch 326/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.8064 - val_accuracy: 0.8097\n",
            "Epoch 327/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.8999 - val_accuracy: 0.7935\n",
            "Epoch 328/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.8159 - val_accuracy: 0.8057\n",
            "Epoch 329/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0208 - accuracy: 0.9914 - val_loss: 0.7860 - val_accuracy: 0.8097\n",
            "Epoch 330/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.7844 - val_accuracy: 0.8178\n",
            "Epoch 331/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.8068 - val_accuracy: 0.8057\n",
            "Epoch 332/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.8356 - val_accuracy: 0.8138\n",
            "Epoch 333/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.8274 - val_accuracy: 0.8097\n",
            "Epoch 334/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0222 - accuracy: 0.9943 - val_loss: 0.8047 - val_accuracy: 0.8057\n",
            "Epoch 335/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0180 - accuracy: 0.9921 - val_loss: 0.8098 - val_accuracy: 0.7976\n",
            "Epoch 336/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.8016 - val_accuracy: 0.8057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 337/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.8476 - val_accuracy: 0.7976\n",
            "Epoch 338/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.8330 - val_accuracy: 0.7976\n",
            "Epoch 339/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.8090 - val_accuracy: 0.8016\n",
            "Epoch 340/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0104 - accuracy: 0.9993 - val_loss: 0.8426 - val_accuracy: 0.8016\n",
            "Epoch 341/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.8104 - val_accuracy: 0.8057\n",
            "Epoch 342/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.8364 - val_accuracy: 0.8016\n",
            "Epoch 343/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.8464 - val_accuracy: 0.8057\n",
            "Epoch 344/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.8633 - val_accuracy: 0.8057\n",
            "Epoch 345/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.8949 - val_accuracy: 0.7814\n",
            "Epoch 346/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0208 - accuracy: 0.9964 - val_loss: 0.8321 - val_accuracy: 0.8138\n",
            "Epoch 347/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.8210 - val_accuracy: 0.8178\n",
            "Epoch 348/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.8708 - val_accuracy: 0.7976\n",
            "Epoch 349/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.8947 - val_accuracy: 0.8057\n",
            "Epoch 350/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.8669 - val_accuracy: 0.8057\n",
            "Epoch 351/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.8698 - val_accuracy: 0.8016\n",
            "Epoch 352/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.8892 - val_accuracy: 0.8016\n",
            "Epoch 353/500\n",
            "1399/1399 [==============================] - 3s 3ms/step - loss: 0.0145 - accuracy: 0.9929 - val_loss: 0.8739 - val_accuracy: 0.8138\n",
            "Epoch 354/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.8417 - val_accuracy: 0.8016\n",
            "Epoch 355/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.8511 - val_accuracy: 0.8016\n",
            "Epoch 356/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.8511 - val_accuracy: 0.7935\n",
            "Epoch 357/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.8374 - val_accuracy: 0.8097\n",
            "Epoch 358/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0137 - accuracy: 0.9943 - val_loss: 0.8498 - val_accuracy: 0.8057\n",
            "Epoch 359/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.8761 - val_accuracy: 0.8016\n",
            "Epoch 360/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.8634 - val_accuracy: 0.8057\n",
            "Epoch 361/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.8661 - val_accuracy: 0.8178\n",
            "Epoch 362/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0215 - accuracy: 0.9950 - val_loss: 0.8414 - val_accuracy: 0.8016\n",
            "Epoch 363/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.8792 - val_accuracy: 0.8097\n",
            "Epoch 364/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0164 - accuracy: 0.9936 - val_loss: 0.8665 - val_accuracy: 0.8097\n",
            "Epoch 365/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0129 - accuracy: 0.9943 - val_loss: 0.8581 - val_accuracy: 0.8057\n",
            "Epoch 366/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.8568 - val_accuracy: 0.8057\n",
            "Epoch 367/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.8524 - val_accuracy: 0.8097\n",
            "Epoch 368/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.8835 - val_accuracy: 0.8057\n",
            "Epoch 369/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.8806 - val_accuracy: 0.8138\n",
            "Epoch 370/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.8835 - val_accuracy: 0.8057\n",
            "Epoch 371/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.8291 - val_accuracy: 0.8178\n",
            "Epoch 372/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.8704 - val_accuracy: 0.8016\n",
            "Epoch 373/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.8761 - val_accuracy: 0.8178\n",
            "Epoch 374/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.8758 - val_accuracy: 0.8097\n",
            "Epoch 375/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.8747 - val_accuracy: 0.8219\n",
            "Epoch 376/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.8766 - val_accuracy: 0.8057\n",
            "Epoch 377/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0173 - accuracy: 0.9929 - val_loss: 0.8794 - val_accuracy: 0.8016\n",
            "Epoch 378/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0161 - accuracy: 0.9936 - val_loss: 0.8360 - val_accuracy: 0.8057\n",
            "Epoch 379/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.8549 - val_accuracy: 0.8178\n",
            "Epoch 380/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.8436 - val_accuracy: 0.8097\n",
            "Epoch 381/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.8437 - val_accuracy: 0.7935\n",
            "Epoch 382/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0120 - accuracy: 0.9943 - val_loss: 0.8373 - val_accuracy: 0.8097\n",
            "Epoch 383/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.8714 - val_accuracy: 0.8138\n",
            "Epoch 384/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9943 - val_loss: 0.8591 - val_accuracy: 0.8057\n",
            "Epoch 385/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.8068 - val_accuracy: 0.8138\n",
            "Epoch 386/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.8127 - val_accuracy: 0.8057\n",
            "Epoch 387/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.8390 - val_accuracy: 0.7976\n",
            "Epoch 388/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0129 - accuracy: 0.9943 - val_loss: 0.8428 - val_accuracy: 0.8138\n",
            "Epoch 389/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.8714 - val_accuracy: 0.8057\n",
            "Epoch 390/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.8693 - val_accuracy: 0.8178\n",
            "Epoch 391/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.8365 - val_accuracy: 0.8138\n",
            "Epoch 392/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.8459 - val_accuracy: 0.8057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 393/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.8544 - val_accuracy: 0.8057\n",
            "Epoch 394/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.8531 - val_accuracy: 0.8057\n",
            "Epoch 395/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.8755 - val_accuracy: 0.8057\n",
            "Epoch 396/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.8759 - val_accuracy: 0.8057\n",
            "Epoch 397/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.8979 - val_accuracy: 0.8097\n",
            "Epoch 398/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 0.8627 - val_accuracy: 0.7854\n",
            "Epoch 399/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0206 - accuracy: 0.9914 - val_loss: 0.8759 - val_accuracy: 0.8016\n",
            "Epoch 400/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.8527 - val_accuracy: 0.8097\n",
            "Epoch 401/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.8781 - val_accuracy: 0.7976\n",
            "Epoch 402/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0115 - accuracy: 0.9986 - val_loss: 0.8708 - val_accuracy: 0.7976\n",
            "Epoch 403/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.9061 - val_accuracy: 0.7976\n",
            "Epoch 404/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.9058 - val_accuracy: 0.7935\n",
            "Epoch 405/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.8654 - val_accuracy: 0.8138\n",
            "Epoch 406/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.8791 - val_accuracy: 0.8097\n",
            "Epoch 407/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0166 - accuracy: 0.9936 - val_loss: 0.8976 - val_accuracy: 0.8097\n",
            "Epoch 408/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0131 - accuracy: 0.9943 - val_loss: 0.8600 - val_accuracy: 0.8016\n",
            "Epoch 409/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.8632 - val_accuracy: 0.8057\n",
            "Epoch 410/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.8925 - val_accuracy: 0.8097\n",
            "Epoch 411/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.8811 - val_accuracy: 0.8057\n",
            "Epoch 412/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0154 - accuracy: 0.9936 - val_loss: 0.8558 - val_accuracy: 0.8057\n",
            "Epoch 413/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.8587 - val_accuracy: 0.8057\n",
            "Epoch 414/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.8798 - val_accuracy: 0.7976\n",
            "Epoch 415/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0129 - accuracy: 0.9943 - val_loss: 0.8641 - val_accuracy: 0.8016\n",
            "Epoch 416/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.8550 - val_accuracy: 0.8097\n",
            "Epoch 417/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.8602 - val_accuracy: 0.8057\n",
            "Epoch 418/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.8521 - val_accuracy: 0.8178\n",
            "Epoch 419/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0126 - accuracy: 0.9943 - val_loss: 0.8624 - val_accuracy: 0.7976\n",
            "Epoch 420/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.8514 - val_accuracy: 0.8016\n",
            "Epoch 421/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.8582 - val_accuracy: 0.8138\n",
            "Epoch 422/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.8763 - val_accuracy: 0.8057\n",
            "Epoch 423/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.9100 - val_accuracy: 0.8016\n",
            "Epoch 424/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0132 - accuracy: 0.9943 - val_loss: 0.8832 - val_accuracy: 0.8138\n",
            "Epoch 425/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.8472 - val_accuracy: 0.8178\n",
            "Epoch 426/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.8502 - val_accuracy: 0.7935\n",
            "Epoch 427/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.8707 - val_accuracy: 0.8016\n",
            "Epoch 428/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.8480 - val_accuracy: 0.8057\n",
            "Epoch 429/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.8675 - val_accuracy: 0.8057\n",
            "Epoch 430/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.8841 - val_accuracy: 0.8097\n",
            "Epoch 431/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.9374 - val_accuracy: 0.8057\n",
            "Epoch 432/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0148 - accuracy: 0.9943 - val_loss: 0.8841 - val_accuracy: 0.8057\n",
            "Epoch 433/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.8814 - val_accuracy: 0.8057\n",
            "Epoch 434/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.8318 - val_accuracy: 0.8138\n",
            "Epoch 435/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.8597 - val_accuracy: 0.8097\n",
            "Epoch 436/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0166 - accuracy: 0.9929 - val_loss: 0.8630 - val_accuracy: 0.8057\n",
            "Epoch 437/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.8269 - val_accuracy: 0.8057\n",
            "Epoch 438/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.8595 - val_accuracy: 0.8138\n",
            "Epoch 439/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.8743 - val_accuracy: 0.8138\n",
            "Epoch 440/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.8773 - val_accuracy: 0.8057\n",
            "Epoch 441/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.8516 - val_accuracy: 0.8178\n",
            "Epoch 442/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0129 - accuracy: 0.9943 - val_loss: 0.8848 - val_accuracy: 0.8057\n",
            "Epoch 443/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.8723 - val_accuracy: 0.8097\n",
            "Epoch 444/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.8688 - val_accuracy: 0.8097\n",
            "Epoch 445/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.8815 - val_accuracy: 0.8057\n",
            "Epoch 446/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.9002 - val_accuracy: 0.8016\n",
            "Epoch 447/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.8897 - val_accuracy: 0.8097\n",
            "Epoch 448/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0177 - accuracy: 0.9921 - val_loss: 0.8666 - val_accuracy: 0.8097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 449/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.8937 - val_accuracy: 0.8097\n",
            "Epoch 450/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0133 - accuracy: 0.9943 - val_loss: 0.9127 - val_accuracy: 0.8097\n",
            "Epoch 451/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.9129 - val_accuracy: 0.8097\n",
            "Epoch 452/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0107 - accuracy: 0.9950 - val_loss: 0.9089 - val_accuracy: 0.8057\n",
            "Epoch 453/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.8958 - val_accuracy: 0.7976\n",
            "Epoch 454/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.9099 - val_accuracy: 0.8097\n",
            "Epoch 455/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0108 - accuracy: 0.9950 - val_loss: 0.9243 - val_accuracy: 0.8057\n",
            "Epoch 456/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0160 - accuracy: 0.9921 - val_loss: 0.8824 - val_accuracy: 0.8178\n",
            "Epoch 457/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.9068 - val_accuracy: 0.8178\n",
            "Epoch 458/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.9034 - val_accuracy: 0.8138\n",
            "Epoch 459/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.9039 - val_accuracy: 0.8219\n",
            "Epoch 460/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.9168 - val_accuracy: 0.8219\n",
            "Epoch 461/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.8906 - val_accuracy: 0.8219\n",
            "Epoch 462/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 0.9053 - val_accuracy: 0.8178\n",
            "Epoch 463/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.9339 - val_accuracy: 0.8178\n",
            "Epoch 464/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.9568 - val_accuracy: 0.8097\n",
            "Epoch 465/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0120 - accuracy: 0.9943 - val_loss: 0.9320 - val_accuracy: 0.8057\n",
            "Epoch 466/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.9096 - val_accuracy: 0.8016\n",
            "Epoch 467/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.9153 - val_accuracy: 0.8138\n",
            "Epoch 468/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.8819 - val_accuracy: 0.8057\n",
            "Epoch 469/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.8976 - val_accuracy: 0.8178\n",
            "Epoch 470/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.8998 - val_accuracy: 0.8057\n",
            "Epoch 471/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.9163 - val_accuracy: 0.8057\n",
            "Epoch 472/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.9156 - val_accuracy: 0.8057\n",
            "Epoch 473/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0151 - accuracy: 0.9929 - val_loss: 0.9002 - val_accuracy: 0.7976\n",
            "Epoch 474/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.8858 - val_accuracy: 0.8016\n",
            "Epoch 475/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.9107 - val_accuracy: 0.8057\n",
            "Epoch 476/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.9622 - val_accuracy: 0.8057\n",
            "Epoch 477/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.9306 - val_accuracy: 0.8097\n",
            "Epoch 478/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.9183 - val_accuracy: 0.8097\n",
            "Epoch 479/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0094 - accuracy: 0.9950 - val_loss: 0.9203 - val_accuracy: 0.8057\n",
            "Epoch 480/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.9156 - val_accuracy: 0.8016\n",
            "Epoch 481/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.8945 - val_accuracy: 0.8016\n",
            "Epoch 482/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.9325 - val_accuracy: 0.8097\n",
            "Epoch 483/500\n",
            "1399/1399 [==============================] - 3s 2ms/step - loss: 0.0104 - accuracy: 0.9950 - val_loss: 0.9054 - val_accuracy: 0.8057\n",
            "Epoch 484/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.8834 - val_accuracy: 0.8057\n",
            "Epoch 485/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.8975 - val_accuracy: 0.8097\n",
            "Epoch 486/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.9115 - val_accuracy: 0.8138\n",
            "Epoch 487/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.9165 - val_accuracy: 0.7976\n",
            "Epoch 488/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.9097 - val_accuracy: 0.8057\n",
            "Epoch 489/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.9171 - val_accuracy: 0.8016\n",
            "Epoch 490/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.9093 - val_accuracy: 0.8097\n",
            "Epoch 491/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.9541 - val_accuracy: 0.8057\n",
            "Epoch 492/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.9132 - val_accuracy: 0.8057\n",
            "Epoch 493/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.9245 - val_accuracy: 0.8138\n",
            "Epoch 494/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.9313 - val_accuracy: 0.8178\n",
            "Epoch 495/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 0.9666 - val_accuracy: 0.8016\n",
            "Epoch 496/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.9644 - val_accuracy: 0.8057\n",
            "Epoch 497/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.9385 - val_accuracy: 0.8138\n",
            "Epoch 498/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 0.9231 - val_accuracy: 0.8097\n",
            "Epoch 499/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.9291 - val_accuracy: 0.8057\n",
            "Epoch 500/500\n",
            "1399/1399 [==============================] - 4s 3ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.9238 - val_accuracy: 0.8057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fba06d75fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJNVn8ocwwIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(\"/content/drive/My Drive/Machine _Hack/janta-hack-CV/test/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTPM_6HiwwIR",
        "colab_type": "code",
        "outputId": "4d597a5f-da1e-47ca-813c-9e3efac90fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_image = []\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "    img = image.load_img('/content/drive/My Drive/Machine _Hack/janta-hack-CV/test/images/'+test['image_names'][i])\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    test_image.append(img)\n",
        "test = np.array(test_image)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/706 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 37/706 [00:00<00:11, 60.32it/s]\u001b[A\n",
            "  6%|▌         | 39/706 [00:01<01:56,  5.74it/s]\u001b[A\n",
            "  6%|▌         | 41/706 [00:02<03:07,  3.55it/s]\u001b[A\n",
            "  6%|▌         | 42/706 [00:03<05:06,  2.16it/s]\u001b[A\n",
            "  6%|▌         | 43/706 [00:04<05:23,  2.05it/s]\u001b[A\n",
            "  6%|▌         | 44/706 [00:04<05:34,  1.98it/s]\u001b[A\n",
            "  6%|▋         | 45/706 [00:05<05:40,  1.94it/s]\u001b[A\n",
            "  7%|▋         | 46/706 [00:05<05:46,  1.90it/s]\u001b[A\n",
            "  7%|▋         | 47/706 [00:06<05:55,  1.85it/s]\u001b[A\n",
            "  7%|▋         | 48/706 [00:07<06:24,  1.71it/s]\u001b[A\n",
            "  7%|▋         | 49/706 [00:07<06:15,  1.75it/s]\u001b[A\n",
            "  7%|▋         | 50/706 [00:08<06:13,  1.76it/s]\u001b[A\n",
            "  7%|▋         | 51/706 [00:08<06:50,  1.60it/s]\u001b[A\n",
            "  7%|▋         | 52/706 [00:09<06:37,  1.64it/s]\u001b[A\n",
            "  8%|▊         | 53/706 [00:10<06:43,  1.62it/s]\u001b[A\n",
            "  8%|▊         | 54/706 [00:10<06:45,  1.61it/s]\u001b[A\n",
            "  8%|▊         | 55/706 [00:11<06:32,  1.66it/s]\u001b[A\n",
            "  8%|▊         | 56/706 [00:12<07:04,  1.53it/s]\u001b[A\n",
            "  8%|▊         | 57/706 [00:12<06:41,  1.61it/s]\u001b[A\n",
            "  8%|▊         | 58/706 [00:13<06:26,  1.67it/s]\u001b[A\n",
            "  8%|▊         | 59/706 [00:13<06:14,  1.73it/s]\u001b[A\n",
            "  8%|▊         | 60/706 [00:14<06:11,  1.74it/s]\u001b[A\n",
            "  9%|▊         | 61/706 [00:14<06:04,  1.77it/s]\u001b[A\n",
            "  9%|▉         | 62/706 [00:15<05:54,  1.81it/s]\u001b[A\n",
            "  9%|▉         | 63/706 [00:15<05:58,  1.79it/s]\u001b[A\n",
            "  9%|▉         | 64/706 [00:16<05:58,  1.79it/s]\u001b[A\n",
            "  9%|▉         | 65/706 [00:17<05:56,  1.80it/s]\u001b[A\n",
            "  9%|▉         | 66/706 [00:17<05:51,  1.82it/s]\u001b[A\n",
            "  9%|▉         | 67/706 [00:18<05:49,  1.83it/s]\u001b[A\n",
            " 10%|▉         | 68/706 [00:18<06:39,  1.60it/s]\u001b[A\n",
            " 10%|▉         | 69/706 [00:19<06:37,  1.60it/s]\u001b[A\n",
            " 10%|▉         | 70/706 [00:20<07:00,  1.51it/s]\u001b[A\n",
            " 10%|█         | 71/706 [00:21<07:20,  1.44it/s]\u001b[A\n",
            " 10%|█         | 72/706 [00:21<07:23,  1.43it/s]\u001b[A\n",
            " 10%|█         | 73/706 [00:22<06:52,  1.53it/s]\u001b[A\n",
            " 10%|█         | 74/706 [00:22<06:30,  1.62it/s]\u001b[A\n",
            " 11%|█         | 75/706 [00:23<06:20,  1.66it/s]\u001b[A\n",
            " 11%|█         | 76/706 [00:24<06:54,  1.52it/s]\u001b[A\n",
            " 11%|█         | 77/706 [00:24<06:29,  1.61it/s]\u001b[A\n",
            " 11%|█         | 78/706 [00:25<06:14,  1.68it/s]\u001b[A\n",
            " 11%|█         | 79/706 [00:25<06:03,  1.72it/s]\u001b[A\n",
            " 11%|█▏        | 80/706 [00:26<06:37,  1.58it/s]\u001b[A\n",
            " 11%|█▏        | 81/706 [00:27<06:20,  1.64it/s]\u001b[A\n",
            " 12%|█▏        | 82/706 [00:27<06:06,  1.70it/s]\u001b[A\n",
            " 12%|█▏        | 83/706 [00:28<05:56,  1.75it/s]\u001b[A\n",
            " 12%|█▏        | 84/706 [00:28<05:47,  1.79it/s]\u001b[A\n",
            " 12%|█▏        | 85/706 [00:29<06:25,  1.61it/s]\u001b[A\n",
            " 12%|█▏        | 86/706 [00:30<06:06,  1.69it/s]\u001b[A\n",
            " 12%|█▏        | 87/706 [00:30<06:00,  1.72it/s]\u001b[A\n",
            " 12%|█▏        | 88/706 [00:31<05:47,  1.78it/s]\u001b[A\n",
            " 13%|█▎        | 89/706 [00:31<06:23,  1.61it/s]\u001b[A\n",
            " 13%|█▎        | 90/706 [00:32<06:59,  1.47it/s]\u001b[A\n",
            " 13%|█▎        | 91/706 [00:33<06:40,  1.54it/s]\u001b[A\n",
            " 13%|█▎        | 92/706 [00:33<06:18,  1.62it/s]\u001b[A\n",
            " 13%|█▎        | 93/706 [00:34<06:17,  1.62it/s]\u001b[A\n",
            " 13%|█▎        | 94/706 [00:34<06:02,  1.69it/s]\u001b[A\n",
            " 13%|█▎        | 95/706 [00:35<05:50,  1.74it/s]\u001b[A\n",
            " 14%|█▎        | 96/706 [00:36<05:43,  1.78it/s]\u001b[A\n",
            " 14%|█▎        | 97/706 [00:36<05:36,  1.81it/s]\u001b[A\n",
            " 14%|█▍        | 98/706 [00:37<06:20,  1.60it/s]\u001b[A\n",
            " 14%|█▍        | 99/706 [00:37<06:03,  1.67it/s]\u001b[A\n",
            " 14%|█▍        | 100/706 [00:38<05:56,  1.70it/s]\u001b[A\n",
            " 14%|█▍        | 101/706 [00:38<05:47,  1.74it/s]\u001b[A\n",
            " 14%|█▍        | 102/706 [00:39<05:42,  1.76it/s]\u001b[A\n",
            " 15%|█▍        | 103/706 [00:40<05:40,  1.77it/s]\u001b[A\n",
            " 15%|█▍        | 104/706 [00:40<05:32,  1.81it/s]\u001b[A\n",
            " 15%|█▍        | 105/706 [00:41<05:25,  1.85it/s]\u001b[A\n",
            " 15%|█▌        | 106/706 [00:41<05:21,  1.87it/s]\u001b[A\n",
            " 15%|█▌        | 107/706 [00:42<05:30,  1.81it/s]\u001b[A\n",
            " 15%|█▌        | 108/706 [00:42<05:29,  1.82it/s]\u001b[A\n",
            " 15%|█▌        | 109/706 [00:43<06:01,  1.65it/s]\u001b[A\n",
            " 16%|█▌        | 110/706 [00:44<05:48,  1.71it/s]\u001b[A\n",
            " 16%|█▌        | 111/706 [00:44<05:41,  1.74it/s]\u001b[A\n",
            " 16%|█▌        | 112/706 [00:45<05:36,  1.76it/s]\u001b[A\n",
            " 16%|█▌        | 113/706 [00:45<05:31,  1.79it/s]\u001b[A\n",
            " 16%|█▌        | 114/706 [00:46<05:29,  1.80it/s]\u001b[A\n",
            " 16%|█▋        | 115/706 [00:46<05:27,  1.80it/s]\u001b[A\n",
            " 16%|█▋        | 116/706 [00:47<05:33,  1.77it/s]\u001b[A\n",
            " 17%|█▋        | 117/706 [00:47<05:29,  1.79it/s]\u001b[A\n",
            " 17%|█▋        | 118/706 [00:48<05:26,  1.80it/s]\u001b[A\n",
            " 17%|█▋        | 119/706 [00:49<05:35,  1.75it/s]\u001b[A\n",
            " 17%|█▋        | 120/706 [00:49<06:22,  1.53it/s]\u001b[A\n",
            " 17%|█▋        | 121/706 [00:50<06:01,  1.62it/s]\u001b[A\n",
            " 17%|█▋        | 122/706 [00:51<05:48,  1.68it/s]\u001b[A\n",
            " 17%|█▋        | 123/706 [00:51<05:40,  1.71it/s]\u001b[A\n",
            " 18%|█▊        | 124/706 [00:52<05:35,  1.73it/s]\u001b[A\n",
            " 18%|█▊        | 125/706 [00:52<05:32,  1.75it/s]\u001b[A\n",
            " 18%|█▊        | 126/706 [00:53<05:24,  1.79it/s]\u001b[A\n",
            " 18%|█▊        | 127/706 [00:53<05:20,  1.81it/s]\u001b[A\n",
            " 18%|█▊        | 128/706 [00:54<05:21,  1.80it/s]\u001b[A\n",
            " 18%|█▊        | 129/706 [00:54<05:16,  1.82it/s]\u001b[A\n",
            " 18%|█▊        | 130/706 [00:55<05:54,  1.63it/s]\u001b[A\n",
            " 19%|█▊        | 131/706 [00:56<05:47,  1.65it/s]\u001b[A\n",
            " 19%|█▊        | 132/706 [00:56<05:38,  1.70it/s]\u001b[A\n",
            " 19%|█▉        | 133/706 [00:57<05:30,  1.74it/s]\u001b[A\n",
            " 19%|█▉        | 134/706 [00:57<05:31,  1.72it/s]\u001b[A\n",
            " 19%|█▉        | 135/706 [00:58<05:25,  1.75it/s]\u001b[A\n",
            " 19%|█▉        | 136/706 [00:59<05:23,  1.76it/s]\u001b[A\n",
            " 19%|█▉        | 137/706 [00:59<05:21,  1.77it/s]\u001b[A\n",
            " 20%|█▉        | 138/706 [01:00<05:14,  1.81it/s]\u001b[A\n",
            " 20%|█▉        | 139/706 [01:00<05:23,  1.75it/s]\u001b[A\n",
            " 20%|█▉        | 140/706 [01:01<05:12,  1.81it/s]\u001b[A\n",
            " 20%|█▉        | 141/706 [01:01<05:43,  1.64it/s]\u001b[A\n",
            " 20%|██        | 142/706 [01:02<05:53,  1.60it/s]\u001b[A\n",
            " 20%|██        | 143/706 [01:03<05:39,  1.66it/s]\u001b[A\n",
            " 20%|██        | 144/706 [01:03<05:59,  1.56it/s]\u001b[A\n",
            " 21%|██        | 145/706 [01:04<05:53,  1.59it/s]\u001b[A\n",
            " 21%|██        | 146/706 [01:05<05:38,  1.66it/s]\u001b[A\n",
            " 21%|██        | 147/706 [01:05<05:25,  1.72it/s]\u001b[A\n",
            " 21%|██        | 148/706 [01:06<05:49,  1.60it/s]\u001b[A\n",
            " 21%|██        | 149/706 [01:06<05:35,  1.66it/s]\u001b[A\n",
            " 21%|██        | 150/706 [01:07<05:27,  1.70it/s]\u001b[A\n",
            " 21%|██▏       | 151/706 [01:08<05:58,  1.55it/s]\u001b[A\n",
            " 22%|██▏       | 152/706 [01:08<05:41,  1.62it/s]\u001b[A\n",
            " 22%|██▏       | 153/706 [01:09<05:26,  1.69it/s]\u001b[A\n",
            " 22%|██▏       | 154/706 [01:10<05:53,  1.56it/s]\u001b[A\n",
            " 22%|██▏       | 155/706 [01:10<05:49,  1.58it/s]\u001b[A\n",
            " 22%|██▏       | 156/706 [01:11<05:35,  1.64it/s]\u001b[A\n",
            " 22%|██▏       | 157/706 [01:11<05:30,  1.66it/s]\u001b[A\n",
            " 22%|██▏       | 158/706 [01:12<05:18,  1.72it/s]\u001b[A\n",
            " 23%|██▎       | 159/706 [01:12<05:12,  1.75it/s]\u001b[A\n",
            " 23%|██▎       | 160/706 [01:13<05:42,  1.59it/s]\u001b[A\n",
            " 23%|██▎       | 161/706 [01:14<05:31,  1.64it/s]\u001b[A\n",
            " 23%|██▎       | 162/706 [01:14<05:29,  1.65it/s]\u001b[A\n",
            " 23%|██▎       | 163/706 [01:15<05:17,  1.71it/s]\u001b[A\n",
            " 23%|██▎       | 164/706 [01:17<08:16,  1.09it/s]\u001b[A\n",
            " 23%|██▎       | 165/706 [01:17<07:13,  1.25it/s]\u001b[A\n",
            " 24%|██▎       | 166/706 [01:18<06:32,  1.38it/s]\u001b[A\n",
            " 24%|██▎       | 167/706 [01:18<06:01,  1.49it/s]\u001b[A\n",
            " 24%|██▍       | 168/706 [01:19<05:47,  1.55it/s]\u001b[A\n",
            " 24%|██▍       | 169/706 [01:19<05:29,  1.63it/s]\u001b[A\n",
            " 24%|██▍       | 170/706 [01:20<05:58,  1.50it/s]\u001b[A\n",
            " 24%|██▍       | 171/706 [01:21<05:33,  1.60it/s]\u001b[A\n",
            " 24%|██▍       | 172/706 [01:21<05:58,  1.49it/s]\u001b[A\n",
            " 25%|██▍       | 173/706 [01:22<05:34,  1.59it/s]\u001b[A\n",
            " 25%|██▍       | 174/706 [01:22<05:19,  1.66it/s]\u001b[A\n",
            " 25%|██▍       | 175/706 [01:23<05:08,  1.72it/s]\u001b[A\n",
            " 25%|██▍       | 176/706 [01:23<04:59,  1.77it/s]\u001b[A\n",
            " 25%|██▌       | 177/706 [01:24<04:55,  1.79it/s]\u001b[A\n",
            " 25%|██▌       | 178/706 [01:25<04:59,  1.76it/s]\u001b[A\n",
            " 25%|██▌       | 179/706 [01:25<04:51,  1.81it/s]\u001b[A\n",
            " 25%|██▌       | 180/706 [01:26<05:29,  1.60it/s]\u001b[A\n",
            " 26%|██▌       | 181/706 [01:27<05:58,  1.47it/s]\u001b[A\n",
            " 26%|██▌       | 182/706 [01:27<05:44,  1.52it/s]\u001b[A\n",
            " 26%|██▌       | 183/706 [01:28<05:24,  1.61it/s]\u001b[A\n",
            " 26%|██▌       | 184/706 [01:28<05:16,  1.65it/s]\u001b[A\n",
            " 26%|██▌       | 185/706 [01:29<05:04,  1.71it/s]\u001b[A\n",
            " 26%|██▋       | 186/706 [01:30<04:54,  1.76it/s]\u001b[A\n",
            " 26%|██▋       | 187/706 [01:30<04:50,  1.79it/s]\u001b[A\n",
            " 27%|██▋       | 188/706 [01:31<04:46,  1.81it/s]\u001b[A\n",
            " 27%|██▋       | 189/706 [01:31<04:45,  1.81it/s]\u001b[A\n",
            " 27%|██▋       | 190/706 [01:32<04:41,  1.83it/s]\u001b[A\n",
            " 27%|██▋       | 191/706 [01:32<05:13,  1.64it/s]\u001b[A\n",
            " 27%|██▋       | 192/706 [01:33<05:06,  1.67it/s]\u001b[A\n",
            " 27%|██▋       | 193/706 [01:34<04:59,  1.71it/s]\u001b[A\n",
            " 27%|██▋       | 194/706 [01:34<05:27,  1.56it/s]\u001b[A\n",
            " 28%|██▊       | 195/706 [01:35<05:10,  1.65it/s]\u001b[A\n",
            " 28%|██▊       | 196/706 [01:35<05:01,  1.69it/s]\u001b[A\n",
            " 28%|██▊       | 197/706 [01:36<04:58,  1.70it/s]\u001b[A\n",
            " 28%|██▊       | 198/706 [01:37<04:54,  1.73it/s]\u001b[A\n",
            " 28%|██▊       | 199/706 [01:37<04:46,  1.77it/s]\u001b[A\n",
            " 28%|██▊       | 200/706 [01:38<04:49,  1.75it/s]\u001b[A\n",
            " 28%|██▊       | 201/706 [01:38<05:20,  1.58it/s]\u001b[A\n",
            " 29%|██▊       | 202/706 [01:39<05:05,  1.65it/s]\u001b[A\n",
            " 29%|██▉       | 203/706 [01:40<04:53,  1.71it/s]\u001b[A\n",
            " 29%|██▉       | 204/706 [01:40<04:45,  1.76it/s]\u001b[A\n",
            " 29%|██▉       | 205/706 [01:41<04:42,  1.77it/s]\u001b[A\n",
            " 29%|██▉       | 206/706 [01:41<04:51,  1.72it/s]\u001b[A\n",
            " 29%|██▉       | 207/706 [01:42<04:46,  1.74it/s]\u001b[A\n",
            " 29%|██▉       | 208/706 [01:42<04:40,  1.78it/s]\u001b[A\n",
            " 30%|██▉       | 209/706 [01:43<04:32,  1.83it/s]\u001b[A\n",
            " 30%|██▉       | 210/706 [01:43<04:32,  1.82it/s]\u001b[A\n",
            " 30%|██▉       | 211/706 [01:44<04:27,  1.85it/s]\u001b[A\n",
            " 30%|███       | 212/706 [01:44<04:25,  1.86it/s]\u001b[A\n",
            " 30%|███       | 213/706 [01:45<04:26,  1.85it/s]\u001b[A\n",
            " 30%|███       | 214/706 [01:46<04:23,  1.87it/s]\u001b[A\n",
            " 30%|███       | 215/706 [01:46<04:28,  1.83it/s]\u001b[A\n",
            " 31%|███       | 216/706 [01:47<04:26,  1.84it/s]\u001b[A\n",
            " 31%|███       | 217/706 [01:47<04:26,  1.83it/s]\u001b[A\n",
            " 31%|███       | 218/706 [01:48<04:27,  1.82it/s]\u001b[A\n",
            " 31%|███       | 219/706 [01:48<04:39,  1.74it/s]\u001b[A\n",
            " 31%|███       | 220/706 [01:49<04:32,  1.78it/s]\u001b[A\n",
            " 31%|███▏      | 221/706 [01:49<04:28,  1.81it/s]\u001b[A\n",
            " 31%|███▏      | 222/706 [01:50<04:31,  1.78it/s]\u001b[A\n",
            " 32%|███▏      | 223/706 [01:51<04:29,  1.79it/s]\u001b[A\n",
            " 32%|███▏      | 224/706 [01:51<04:45,  1.69it/s]\u001b[A\n",
            " 32%|███▏      | 225/706 [01:52<05:08,  1.56it/s]\u001b[A\n",
            " 32%|███▏      | 226/706 [01:53<05:23,  1.48it/s]\u001b[A\n",
            " 32%|███▏      | 227/706 [01:53<05:05,  1.57it/s]\u001b[A\n",
            " 32%|███▏      | 228/706 [01:54<04:52,  1.64it/s]\u001b[A\n",
            " 32%|███▏      | 229/706 [01:55<05:11,  1.53it/s]\u001b[A\n",
            " 33%|███▎      | 230/706 [01:55<05:00,  1.59it/s]\u001b[A\n",
            " 33%|███▎      | 231/706 [01:56<04:46,  1.66it/s]\u001b[A\n",
            " 33%|███▎      | 232/706 [01:56<04:35,  1.72it/s]\u001b[A\n",
            " 33%|███▎      | 233/706 [01:57<04:55,  1.60it/s]\u001b[A\n",
            " 33%|███▎      | 234/706 [01:58<04:45,  1.66it/s]\u001b[A\n",
            " 33%|███▎      | 235/706 [01:58<04:41,  1.68it/s]\u001b[A\n",
            " 33%|███▎      | 236/706 [01:59<04:37,  1.70it/s]\u001b[A\n",
            " 34%|███▎      | 237/706 [01:59<04:23,  1.78it/s]\u001b[A\n",
            " 34%|███▎      | 238/706 [02:00<04:47,  1.63it/s]\u001b[A\n",
            " 34%|███▍      | 239/706 [02:00<04:35,  1.69it/s]\u001b[A\n",
            " 34%|███▍      | 240/706 [02:01<04:30,  1.72it/s]\u001b[A\n",
            " 34%|███▍      | 241/706 [02:02<04:34,  1.69it/s]\u001b[A\n",
            " 34%|███▍      | 242/706 [02:02<04:26,  1.74it/s]\u001b[A\n",
            " 34%|███▍      | 243/706 [02:03<04:22,  1.77it/s]\u001b[A\n",
            " 35%|███▍      | 244/706 [02:03<04:15,  1.81it/s]\u001b[A\n",
            " 35%|███▍      | 245/706 [02:04<04:45,  1.61it/s]\u001b[A\n",
            " 35%|███▍      | 246/706 [02:05<04:32,  1.69it/s]\u001b[A\n",
            " 35%|███▍      | 247/706 [02:05<04:23,  1.74it/s]\u001b[A\n",
            " 35%|███▌      | 248/706 [02:06<04:19,  1.77it/s]\u001b[A\n",
            " 35%|███▌      | 249/706 [02:06<04:14,  1.80it/s]\u001b[A\n",
            " 35%|███▌      | 250/706 [02:07<04:46,  1.59it/s]\u001b[A\n",
            " 36%|███▌      | 251/706 [02:08<05:04,  1.50it/s]\u001b[A\n",
            " 36%|███▌      | 252/706 [02:08<04:48,  1.58it/s]\u001b[A\n",
            " 36%|███▌      | 253/706 [02:09<04:34,  1.65it/s]\u001b[A\n",
            " 36%|███▌      | 254/706 [02:09<04:39,  1.61it/s]\u001b[A\n",
            " 36%|███▌      | 255/706 [02:10<04:30,  1.67it/s]\u001b[A\n",
            " 36%|███▋      | 256/706 [02:11<04:22,  1.72it/s]\u001b[A\n",
            " 36%|███▋      | 257/706 [02:11<04:14,  1.76it/s]\u001b[A\n",
            " 37%|███▋      | 258/706 [02:12<04:10,  1.79it/s]\u001b[A\n",
            " 37%|███▋      | 259/706 [02:12<04:05,  1.82it/s]\u001b[A\n",
            " 37%|███▋      | 260/706 [02:13<04:01,  1.84it/s]\u001b[A\n",
            " 37%|███▋      | 261/706 [02:13<04:30,  1.64it/s]\u001b[A\n",
            " 37%|███▋      | 262/706 [02:14<04:24,  1.68it/s]\u001b[A\n",
            " 37%|███▋      | 263/706 [02:15<04:15,  1.73it/s]\u001b[A\n",
            " 37%|███▋      | 264/706 [02:15<04:12,  1.75it/s]\u001b[A\n",
            " 38%|███▊      | 265/706 [02:16<04:14,  1.73it/s]\u001b[A\n",
            " 38%|███▊      | 266/706 [02:16<04:39,  1.57it/s]\u001b[A\n",
            " 38%|███▊      | 267/706 [02:17<04:25,  1.65it/s]\u001b[A\n",
            " 38%|███▊      | 268/706 [02:18<04:17,  1.70it/s]\u001b[A\n",
            " 38%|███▊      | 269/706 [02:18<04:10,  1.74it/s]\u001b[A\n",
            " 38%|███▊      | 270/706 [02:19<04:30,  1.61it/s]\u001b[A\n",
            " 38%|███▊      | 271/706 [02:19<04:24,  1.64it/s]\u001b[A\n",
            " 39%|███▊      | 272/706 [02:20<04:15,  1.70it/s]\u001b[A\n",
            " 39%|███▊      | 273/706 [02:20<04:08,  1.74it/s]\u001b[A\n",
            " 39%|███▉      | 274/706 [02:21<04:02,  1.78it/s]\u001b[A\n",
            " 39%|███▉      | 275/706 [02:21<03:53,  1.84it/s]\u001b[A\n",
            " 39%|███▉      | 276/706 [02:22<03:55,  1.83it/s]\u001b[A\n",
            " 39%|███▉      | 277/706 [02:23<03:57,  1.80it/s]\u001b[A\n",
            " 39%|███▉      | 278/706 [02:23<03:53,  1.83it/s]\u001b[A\n",
            " 40%|███▉      | 279/706 [02:24<04:15,  1.67it/s]\u001b[A\n",
            " 40%|███▉      | 280/706 [02:24<04:18,  1.65it/s]\u001b[A\n",
            " 40%|███▉      | 281/706 [02:25<04:38,  1.53it/s]\u001b[A\n",
            " 40%|███▉      | 282/706 [02:26<04:28,  1.58it/s]\u001b[A\n",
            " 40%|████      | 283/706 [02:27<04:46,  1.48it/s]\u001b[A\n",
            " 40%|████      | 284/706 [02:27<04:26,  1.58it/s]\u001b[A\n",
            " 40%|████      | 285/706 [02:28<04:16,  1.64it/s]\u001b[A\n",
            " 41%|████      | 286/706 [02:28<04:09,  1.68it/s]\u001b[A\n",
            " 41%|████      | 287/706 [02:29<04:29,  1.56it/s]\u001b[A\n",
            " 41%|████      | 288/706 [02:30<04:14,  1.64it/s]\u001b[A\n",
            " 41%|████      | 289/706 [02:30<04:25,  1.57it/s]\u001b[A\n",
            " 41%|████      | 290/706 [02:31<04:13,  1.64it/s]\u001b[A\n",
            " 41%|████      | 291/706 [02:31<04:01,  1.72it/s]\u001b[A\n",
            " 41%|████▏     | 292/706 [02:32<03:50,  1.80it/s]\u001b[A\n",
            " 42%|████▏     | 293/706 [02:32<03:48,  1.81it/s]\u001b[A\n",
            " 42%|████▏     | 294/706 [02:33<03:41,  1.86it/s]\u001b[A\n",
            " 42%|████▏     | 295/706 [02:33<03:39,  1.87it/s]\u001b[A\n",
            " 42%|████▏     | 296/706 [02:34<03:39,  1.87it/s]\u001b[A\n",
            " 42%|████▏     | 297/706 [02:35<04:05,  1.67it/s]\u001b[A\n",
            " 42%|████▏     | 298/706 [02:35<03:58,  1.71it/s]\u001b[A\n",
            " 42%|████▏     | 299/706 [02:36<04:18,  1.58it/s]\u001b[A\n",
            " 42%|████▏     | 300/706 [02:37<04:07,  1.64it/s]\u001b[A\n",
            " 43%|████▎     | 301/706 [02:37<03:57,  1.71it/s]\u001b[A\n",
            " 43%|████▎     | 302/706 [02:38<03:56,  1.71it/s]\u001b[A\n",
            " 43%|████▎     | 303/706 [02:38<03:48,  1.77it/s]\u001b[A\n",
            " 43%|████▎     | 304/706 [02:39<03:44,  1.79it/s]\u001b[A\n",
            " 43%|████▎     | 305/706 [02:39<03:40,  1.82it/s]\u001b[A\n",
            " 43%|████▎     | 306/706 [02:40<03:39,  1.82it/s]\u001b[A\n",
            " 43%|████▎     | 307/706 [02:41<04:01,  1.65it/s]\u001b[A\n",
            " 44%|████▎     | 308/706 [02:41<03:51,  1.72it/s]\u001b[A\n",
            " 44%|████▍     | 309/706 [02:42<03:48,  1.74it/s]\u001b[A\n",
            " 44%|████▍     | 310/706 [02:42<04:23,  1.50it/s]\u001b[A\n",
            " 44%|████▍     | 311/706 [02:43<04:09,  1.59it/s]\u001b[A\n",
            " 44%|████▍     | 312/706 [02:44<03:56,  1.67it/s]\u001b[A\n",
            " 44%|████▍     | 313/706 [02:44<03:49,  1.71it/s]\u001b[A\n",
            " 44%|████▍     | 314/706 [02:45<04:06,  1.59it/s]\u001b[A\n",
            " 45%|████▍     | 315/706 [02:45<03:54,  1.67it/s]\u001b[A\n",
            " 45%|████▍     | 316/706 [02:46<03:46,  1.72it/s]\u001b[A\n",
            " 45%|████▍     | 317/706 [02:46<03:42,  1.75it/s]\u001b[A\n",
            " 45%|████▌     | 318/706 [02:47<03:46,  1.72it/s]\u001b[A\n",
            " 45%|████▌     | 319/706 [02:48<03:40,  1.75it/s]\u001b[A\n",
            " 45%|████▌     | 320/706 [02:48<03:32,  1.81it/s]\u001b[A\n",
            " 45%|████▌     | 321/706 [02:49<03:29,  1.84it/s]\u001b[A\n",
            " 46%|████▌     | 322/706 [02:49<03:56,  1.63it/s]\u001b[A\n",
            " 46%|████▌     | 323/706 [02:50<03:46,  1.69it/s]\u001b[A\n",
            " 46%|████▌     | 324/706 [02:51<03:43,  1.71it/s]\u001b[A\n",
            " 46%|████▌     | 325/706 [02:51<03:34,  1.77it/s]\u001b[A\n",
            " 46%|████▌     | 326/706 [02:52<03:35,  1.77it/s]\u001b[A\n",
            " 46%|████▋     | 327/706 [02:52<03:38,  1.74it/s]\u001b[A\n",
            " 46%|████▋     | 328/706 [02:53<04:00,  1.57it/s]\u001b[A\n",
            " 47%|████▋     | 329/706 [02:54<03:46,  1.66it/s]\u001b[A\n",
            " 47%|████▋     | 330/706 [02:54<03:34,  1.75it/s]\u001b[A\n",
            " 47%|████▋     | 331/706 [02:55<03:26,  1.81it/s]\u001b[A\n",
            " 47%|████▋     | 332/706 [02:55<03:52,  1.61it/s]\u001b[A\n",
            " 47%|████▋     | 333/706 [02:56<03:42,  1.68it/s]\u001b[A\n",
            " 47%|████▋     | 334/706 [02:56<03:34,  1.73it/s]\u001b[A\n",
            " 47%|████▋     | 335/706 [02:57<03:29,  1.77it/s]\u001b[A\n",
            " 48%|████▊     | 336/706 [02:57<03:22,  1.83it/s]\u001b[A\n",
            " 48%|████▊     | 337/706 [02:58<03:20,  1.84it/s]\u001b[A\n",
            " 48%|████▊     | 338/706 [02:58<03:15,  1.88it/s]\u001b[A\n",
            " 48%|████▊     | 339/706 [02:59<03:19,  1.84it/s]\u001b[A\n",
            " 48%|████▊     | 340/706 [03:00<03:18,  1.84it/s]\u001b[A\n",
            " 48%|████▊     | 341/706 [03:00<03:49,  1.59it/s]\u001b[A\n",
            " 48%|████▊     | 342/706 [03:01<04:13,  1.44it/s]\u001b[A\n",
            " 49%|████▊     | 343/706 [03:02<03:49,  1.58it/s]\u001b[A\n",
            " 49%|████▊     | 344/706 [03:02<03:46,  1.59it/s]\u001b[A\n",
            " 49%|████▉     | 345/706 [03:03<03:36,  1.67it/s]\u001b[A\n",
            " 49%|████▉     | 346/706 [03:03<03:28,  1.73it/s]\u001b[A\n",
            " 49%|████▉     | 347/706 [03:04<03:21,  1.78it/s]\u001b[A\n",
            " 49%|████▉     | 348/706 [03:05<03:44,  1.60it/s]\u001b[A\n",
            " 49%|████▉     | 349/706 [03:05<03:34,  1.66it/s]\u001b[A\n",
            " 50%|████▉     | 350/706 [03:06<03:30,  1.69it/s]\u001b[A\n",
            " 50%|████▉     | 351/706 [03:06<03:27,  1.71it/s]\u001b[A\n",
            " 50%|████▉     | 352/706 [03:07<03:31,  1.68it/s]\u001b[A\n",
            " 50%|█████     | 353/706 [03:08<03:48,  1.55it/s]\u001b[A\n",
            " 50%|█████     | 354/706 [03:09<03:59,  1.47it/s]\u001b[A\n",
            " 50%|█████     | 355/706 [03:09<03:39,  1.60it/s]\u001b[A\n",
            " 50%|█████     | 356/706 [03:10<04:01,  1.45it/s]\u001b[A\n",
            " 51%|█████     | 357/706 [03:10<03:43,  1.56it/s]\u001b[A\n",
            " 51%|█████     | 358/706 [03:11<03:36,  1.61it/s]\u001b[A\n",
            " 51%|█████     | 359/706 [03:12<04:30,  1.28it/s]\u001b[A\n",
            " 51%|█████     | 360/706 [03:13<04:02,  1.43it/s]\u001b[A\n",
            " 51%|█████     | 361/706 [03:13<03:43,  1.54it/s]\u001b[A\n",
            " 51%|█████▏    | 362/706 [03:14<03:35,  1.60it/s]\u001b[A\n",
            " 51%|█████▏    | 363/706 [03:15<03:51,  1.48it/s]\u001b[A\n",
            " 52%|█████▏    | 364/706 [03:15<03:34,  1.59it/s]\u001b[A\n",
            " 52%|█████▏    | 365/706 [03:16<03:25,  1.66it/s]\u001b[A\n",
            " 52%|█████▏    | 366/706 [03:16<03:21,  1.69it/s]\u001b[A\n",
            " 52%|█████▏    | 367/706 [03:17<03:17,  1.72it/s]\u001b[A\n",
            " 52%|█████▏    | 368/706 [03:17<03:11,  1.77it/s]\u001b[A\n",
            " 52%|█████▏    | 369/706 [03:18<03:40,  1.53it/s]\u001b[A\n",
            " 52%|█████▏    | 370/706 [03:19<03:28,  1.61it/s]\u001b[A\n",
            " 53%|█████▎    | 371/706 [03:19<03:17,  1.69it/s]\u001b[A\n",
            " 53%|█████▎    | 372/706 [03:20<03:11,  1.74it/s]\u001b[A\n",
            " 53%|█████▎    | 373/706 [03:20<03:08,  1.77it/s]\u001b[A\n",
            " 53%|█████▎    | 374/706 [03:21<03:01,  1.83it/s]\u001b[A\n",
            " 53%|█████▎    | 375/706 [03:21<03:03,  1.80it/s]\u001b[A\n",
            " 53%|█████▎    | 376/706 [03:22<03:20,  1.64it/s]\u001b[A\n",
            " 53%|█████▎    | 377/706 [03:23<03:09,  1.73it/s]\u001b[A\n",
            " 54%|█████▎    | 378/706 [03:23<03:07,  1.75it/s]\u001b[A\n",
            " 54%|█████▎    | 379/706 [03:24<02:59,  1.82it/s]\u001b[A\n",
            " 54%|█████▍    | 380/706 [03:24<02:58,  1.83it/s]\u001b[A\n",
            " 54%|█████▍    | 381/706 [03:25<03:15,  1.66it/s]\u001b[A\n",
            " 54%|█████▍    | 382/706 [03:26<03:26,  1.57it/s]\u001b[A\n",
            " 54%|█████▍    | 383/706 [03:26<03:17,  1.64it/s]\u001b[A\n",
            " 54%|█████▍    | 384/706 [03:27<03:27,  1.55it/s]\u001b[A\n",
            " 55%|█████▍    | 385/706 [03:27<03:15,  1.64it/s]\u001b[A\n",
            " 55%|█████▍    | 386/706 [03:28<03:09,  1.68it/s]\u001b[A\n",
            " 55%|█████▍    | 387/706 [03:29<03:04,  1.73it/s]\u001b[A\n",
            " 55%|█████▍    | 388/706 [03:29<02:57,  1.79it/s]\u001b[A\n",
            " 55%|█████▌    | 389/706 [03:30<02:54,  1.82it/s]\u001b[A\n",
            " 55%|█████▌    | 390/706 [03:30<02:52,  1.83it/s]\u001b[A\n",
            " 55%|█████▌    | 391/706 [03:31<02:49,  1.86it/s]\u001b[A\n",
            " 56%|█████▌    | 392/706 [03:31<02:49,  1.85it/s]\u001b[A\n",
            " 56%|█████▌    | 393/706 [03:32<02:50,  1.83it/s]\u001b[A\n",
            " 56%|█████▌    | 394/706 [03:32<02:49,  1.84it/s]\u001b[A\n",
            " 56%|█████▌    | 395/706 [03:33<02:48,  1.85it/s]\u001b[A\n",
            " 56%|█████▌    | 396/706 [03:33<02:47,  1.86it/s]\u001b[A\n",
            " 56%|█████▌    | 397/706 [03:34<03:06,  1.66it/s]\u001b[A\n",
            " 56%|█████▋    | 398/706 [03:35<02:59,  1.71it/s]\u001b[A\n",
            " 57%|█████▋    | 399/706 [03:35<02:59,  1.71it/s]\u001b[A\n",
            " 57%|█████▋    | 400/706 [03:36<02:58,  1.72it/s]\u001b[A\n",
            " 57%|█████▋    | 401/706 [03:36<02:49,  1.80it/s]\u001b[A\n",
            " 57%|█████▋    | 402/706 [03:37<02:47,  1.81it/s]\u001b[A\n",
            " 57%|█████▋    | 403/706 [03:37<02:46,  1.82it/s]\u001b[A\n",
            " 57%|█████▋    | 404/706 [03:38<02:44,  1.84it/s]\u001b[A\n",
            " 57%|█████▋    | 405/706 [03:38<02:42,  1.85it/s]\u001b[A\n",
            " 58%|█████▊    | 406/706 [03:39<02:41,  1.85it/s]\u001b[A\n",
            " 58%|█████▊    | 407/706 [03:39<02:42,  1.84it/s]\u001b[A\n",
            " 58%|█████▊    | 408/706 [03:40<02:45,  1.80it/s]\u001b[A\n",
            " 58%|█████▊    | 409/706 [03:41<02:45,  1.79it/s]\u001b[A\n",
            " 58%|█████▊    | 410/706 [03:41<02:43,  1.82it/s]\u001b[A\n",
            " 58%|█████▊    | 411/706 [03:42<02:43,  1.81it/s]\u001b[A\n",
            " 58%|█████▊    | 412/706 [03:42<02:39,  1.85it/s]\u001b[A\n",
            " 58%|█████▊    | 413/706 [03:43<02:35,  1.88it/s]\u001b[A\n",
            " 59%|█████▊    | 414/706 [03:43<02:36,  1.86it/s]\u001b[A\n",
            " 59%|█████▉    | 415/706 [03:44<02:42,  1.79it/s]\u001b[A\n",
            " 59%|█████▉    | 416/706 [03:45<03:08,  1.54it/s]\u001b[A\n",
            " 59%|█████▉    | 417/706 [03:45<02:58,  1.62it/s]\u001b[A\n",
            " 59%|█████▉    | 418/706 [03:46<02:54,  1.65it/s]\u001b[A\n",
            " 59%|█████▉    | 419/706 [03:47<03:09,  1.51it/s]\u001b[A\n",
            " 59%|█████▉    | 420/706 [03:47<02:56,  1.62it/s]\u001b[A\n",
            " 60%|█████▉    | 421/706 [03:48<02:56,  1.62it/s]\u001b[A\n",
            " 60%|█████▉    | 422/706 [03:48<02:49,  1.67it/s]\u001b[A\n",
            " 60%|█████▉    | 423/706 [03:49<02:42,  1.74it/s]\u001b[A\n",
            " 60%|██████    | 424/706 [03:50<03:01,  1.56it/s]\u001b[A\n",
            " 60%|██████    | 425/706 [03:50<03:07,  1.49it/s]\u001b[A\n",
            " 60%|██████    | 426/706 [03:51<03:14,  1.44it/s]\u001b[A\n",
            " 60%|██████    | 427/706 [03:52<03:01,  1.54it/s]\u001b[A\n",
            " 61%|██████    | 428/706 [03:52<02:47,  1.66it/s]\u001b[A\n",
            " 61%|██████    | 429/706 [03:53<02:41,  1.71it/s]\u001b[A\n",
            " 61%|██████    | 430/706 [03:53<02:37,  1.75it/s]\u001b[A\n",
            " 61%|██████    | 431/706 [03:54<02:34,  1.78it/s]\u001b[A\n",
            " 61%|██████    | 432/706 [03:55<02:52,  1.59it/s]\u001b[A\n",
            " 61%|██████▏   | 433/706 [03:55<02:45,  1.65it/s]\u001b[A\n",
            " 61%|██████▏   | 434/706 [03:56<02:39,  1.71it/s]\u001b[A\n",
            " 62%|██████▏   | 435/706 [03:56<02:35,  1.74it/s]\u001b[A\n",
            " 62%|██████▏   | 436/706 [03:57<02:33,  1.76it/s]\u001b[A\n",
            " 62%|██████▏   | 437/706 [03:58<02:48,  1.60it/s]\u001b[A\n",
            " 62%|██████▏   | 438/706 [03:58<02:43,  1.64it/s]\u001b[A\n",
            " 62%|██████▏   | 439/706 [03:59<02:53,  1.54it/s]\u001b[A\n",
            " 62%|██████▏   | 440/706 [03:59<02:44,  1.62it/s]\u001b[A\n",
            " 62%|██████▏   | 441/706 [04:00<02:36,  1.69it/s]\u001b[A\n",
            " 63%|██████▎   | 442/706 [04:00<02:30,  1.76it/s]\u001b[A\n",
            " 63%|██████▎   | 443/706 [04:01<02:48,  1.56it/s]\u001b[A\n",
            " 63%|██████▎   | 444/706 [04:02<02:38,  1.65it/s]\u001b[A\n",
            " 63%|██████▎   | 445/706 [04:03<02:49,  1.54it/s]\u001b[A\n",
            " 63%|██████▎   | 446/706 [04:03<02:38,  1.64it/s]\u001b[A\n",
            " 63%|██████▎   | 447/706 [04:04<02:32,  1.70it/s]\u001b[A\n",
            " 63%|██████▎   | 448/706 [04:04<02:29,  1.73it/s]\u001b[A\n",
            " 64%|██████▎   | 449/706 [04:05<02:24,  1.77it/s]\u001b[A\n",
            " 64%|██████▎   | 450/706 [04:05<02:24,  1.77it/s]\u001b[A\n",
            " 64%|██████▍   | 451/706 [04:06<02:21,  1.80it/s]\u001b[A\n",
            " 64%|██████▍   | 452/706 [04:06<02:19,  1.82it/s]\u001b[A\n",
            " 64%|██████▍   | 453/706 [04:07<02:19,  1.81it/s]\u001b[A\n",
            " 64%|██████▍   | 454/706 [04:08<02:22,  1.77it/s]\u001b[A\n",
            " 64%|██████▍   | 455/706 [04:08<02:20,  1.79it/s]\u001b[A\n",
            " 65%|██████▍   | 456/706 [04:09<02:17,  1.81it/s]\u001b[A\n",
            " 65%|██████▍   | 457/706 [04:09<02:15,  1.84it/s]\u001b[A\n",
            " 65%|██████▍   | 458/706 [04:10<02:16,  1.82it/s]\u001b[A\n",
            " 65%|██████▌   | 459/706 [04:10<02:30,  1.64it/s]\u001b[A\n",
            " 65%|██████▌   | 460/706 [04:11<02:24,  1.70it/s]\u001b[A\n",
            " 65%|██████▌   | 461/706 [04:11<02:20,  1.75it/s]\u001b[A\n",
            " 65%|██████▌   | 462/706 [04:12<02:18,  1.77it/s]\u001b[A\n",
            " 66%|██████▌   | 463/706 [04:13<02:17,  1.77it/s]\u001b[A\n",
            " 66%|██████▌   | 464/706 [04:13<02:15,  1.78it/s]\u001b[A\n",
            " 66%|██████▌   | 465/706 [04:14<02:31,  1.60it/s]\u001b[A\n",
            " 66%|██████▌   | 466/706 [04:15<02:26,  1.64it/s]\u001b[A\n",
            " 66%|██████▌   | 467/706 [04:15<02:35,  1.54it/s]\u001b[A\n",
            " 66%|██████▋   | 468/706 [04:16<02:27,  1.62it/s]\u001b[A\n",
            " 66%|██████▋   | 469/706 [04:16<02:18,  1.71it/s]\u001b[A\n",
            " 67%|██████▋   | 470/706 [04:17<02:13,  1.76it/s]\u001b[A\n",
            " 67%|██████▋   | 471/706 [04:17<02:11,  1.78it/s]\u001b[A\n",
            " 67%|██████▋   | 472/706 [04:18<02:08,  1.82it/s]\u001b[A\n",
            " 67%|██████▋   | 473/706 [04:19<02:22,  1.64it/s]\u001b[A\n",
            " 67%|██████▋   | 474/706 [04:19<02:16,  1.70it/s]\u001b[A\n",
            " 67%|██████▋   | 475/706 [04:20<02:12,  1.74it/s]\u001b[A\n",
            " 67%|██████▋   | 476/706 [04:20<02:09,  1.78it/s]\u001b[A\n",
            " 68%|██████▊   | 477/706 [04:21<02:06,  1.82it/s]\u001b[A\n",
            " 68%|██████▊   | 478/706 [04:21<02:03,  1.84it/s]\u001b[A\n",
            " 68%|██████▊   | 479/706 [04:22<02:20,  1.61it/s]\u001b[A\n",
            " 68%|██████▊   | 480/706 [04:23<02:18,  1.63it/s]\u001b[A\n",
            " 68%|██████▊   | 481/706 [04:23<02:14,  1.67it/s]\u001b[A\n",
            " 68%|██████▊   | 482/706 [04:24<02:11,  1.71it/s]\u001b[A\n",
            " 68%|██████▊   | 483/706 [04:24<02:11,  1.70it/s]\u001b[A\n",
            " 69%|██████▊   | 484/706 [04:25<02:06,  1.75it/s]\u001b[A\n",
            " 69%|██████▊   | 485/706 [04:25<02:03,  1.79it/s]\u001b[A\n",
            " 69%|██████▉   | 486/706 [04:26<02:03,  1.78it/s]\u001b[A\n",
            " 69%|██████▉   | 487/706 [04:27<02:12,  1.66it/s]\u001b[A\n",
            " 69%|██████▉   | 488/706 [04:27<02:08,  1.70it/s]\u001b[A\n",
            " 69%|██████▉   | 489/706 [04:28<02:05,  1.73it/s]\u001b[A\n",
            " 69%|██████▉   | 490/706 [04:29<02:18,  1.56it/s]\u001b[A\n",
            " 70%|██████▉   | 491/706 [04:29<02:10,  1.64it/s]\u001b[A\n",
            " 70%|██████▉   | 492/706 [04:30<02:21,  1.51it/s]\u001b[A\n",
            " 70%|██████▉   | 493/706 [04:31<02:16,  1.56it/s]\u001b[A\n",
            " 70%|██████▉   | 494/706 [04:31<02:09,  1.64it/s]\u001b[A\n",
            " 70%|███████   | 495/706 [04:32<02:03,  1.71it/s]\u001b[A\n",
            " 70%|███████   | 496/706 [04:32<01:59,  1.76it/s]\u001b[A\n",
            " 70%|███████   | 497/706 [04:33<02:08,  1.63it/s]\u001b[A\n",
            " 71%|███████   | 498/706 [04:34<02:16,  1.53it/s]\u001b[A\n",
            " 71%|███████   | 499/706 [04:34<02:10,  1.59it/s]\u001b[A\n",
            " 71%|███████   | 500/706 [04:35<02:03,  1.67it/s]\u001b[A\n",
            " 71%|███████   | 501/706 [04:35<02:10,  1.57it/s]\u001b[A\n",
            " 71%|███████   | 502/706 [04:36<02:02,  1.67it/s]\u001b[A\n",
            " 71%|███████   | 503/706 [04:36<01:57,  1.73it/s]\u001b[A\n",
            " 71%|███████▏  | 504/706 [04:37<02:09,  1.56it/s]\u001b[A\n",
            " 72%|███████▏  | 505/706 [04:39<02:46,  1.20it/s]\u001b[A\n",
            " 72%|███████▏  | 506/706 [04:39<02:31,  1.32it/s]\u001b[A\n",
            " 72%|███████▏  | 507/706 [04:40<02:17,  1.45it/s]\u001b[A\n",
            " 72%|███████▏  | 508/706 [04:40<02:23,  1.38it/s]\u001b[A\n",
            " 72%|███████▏  | 509/706 [04:41<02:11,  1.50it/s]\u001b[A\n",
            " 72%|███████▏  | 510/706 [04:42<02:02,  1.60it/s]\u001b[A\n",
            " 72%|███████▏  | 511/706 [04:42<01:56,  1.67it/s]\u001b[A\n",
            " 73%|███████▎  | 512/706 [04:43<02:09,  1.50it/s]\u001b[A\n",
            " 73%|███████▎  | 513/706 [04:44<02:12,  1.45it/s]\u001b[A\n",
            " 73%|███████▎  | 514/706 [04:44<02:03,  1.55it/s]\u001b[A\n",
            " 73%|███████▎  | 515/706 [04:45<01:57,  1.63it/s]\u001b[A\n",
            " 73%|███████▎  | 516/706 [04:45<01:52,  1.69it/s]\u001b[A\n",
            " 73%|███████▎  | 517/706 [04:46<01:48,  1.74it/s]\u001b[A\n",
            " 73%|███████▎  | 518/706 [04:47<01:58,  1.59it/s]\u001b[A\n",
            " 74%|███████▎  | 519/706 [04:47<01:52,  1.67it/s]\u001b[A\n",
            " 74%|███████▎  | 520/706 [04:48<01:50,  1.68it/s]\u001b[A\n",
            " 74%|███████▍  | 521/706 [04:48<01:59,  1.55it/s]\u001b[A\n",
            " 74%|███████▍  | 522/706 [04:49<01:57,  1.57it/s]\u001b[A\n",
            " 74%|███████▍  | 523/706 [04:50<02:02,  1.49it/s]\u001b[A\n",
            " 74%|███████▍  | 524/706 [04:50<01:54,  1.59it/s]\u001b[A\n",
            " 74%|███████▍  | 525/706 [04:51<01:49,  1.66it/s]\u001b[A\n",
            " 75%|███████▍  | 526/706 [04:51<01:46,  1.69it/s]\u001b[A\n",
            " 75%|███████▍  | 527/706 [04:52<01:43,  1.72it/s]\u001b[A\n",
            " 75%|███████▍  | 528/706 [04:53<01:53,  1.57it/s]\u001b[A\n",
            " 75%|███████▍  | 529/706 [04:53<01:47,  1.65it/s]\u001b[A\n",
            " 75%|███████▌  | 530/706 [04:54<01:43,  1.70it/s]\u001b[A\n",
            " 75%|███████▌  | 531/706 [04:54<01:40,  1.75it/s]\u001b[A\n",
            " 75%|███████▌  | 532/706 [04:55<01:38,  1.78it/s]\u001b[A\n",
            " 75%|███████▌  | 533/706 [04:56<01:50,  1.57it/s]\u001b[A\n",
            " 76%|███████▌  | 534/706 [04:56<01:44,  1.65it/s]\u001b[A\n",
            " 76%|███████▌  | 535/706 [04:57<01:52,  1.53it/s]\u001b[A\n",
            " 76%|███████▌  | 536/706 [04:58<01:45,  1.62it/s]\u001b[A\n",
            " 76%|███████▌  | 537/706 [04:58<01:40,  1.68it/s]\u001b[A\n",
            " 76%|███████▌  | 538/706 [04:59<01:39,  1.68it/s]\u001b[A\n",
            " 76%|███████▋  | 539/706 [04:59<01:35,  1.74it/s]\u001b[A\n",
            " 76%|███████▋  | 540/706 [05:00<01:34,  1.75it/s]\u001b[A\n",
            " 77%|███████▋  | 541/706 [05:00<01:33,  1.77it/s]\u001b[A\n",
            " 77%|███████▋  | 542/706 [05:01<01:33,  1.75it/s]\u001b[A\n",
            " 77%|███████▋  | 543/706 [05:01<01:31,  1.77it/s]\u001b[A\n",
            " 77%|███████▋  | 544/706 [05:02<01:29,  1.82it/s]\u001b[A\n",
            " 77%|███████▋  | 545/706 [05:03<01:28,  1.83it/s]\u001b[A\n",
            " 77%|███████▋  | 546/706 [05:03<01:29,  1.79it/s]\u001b[A\n",
            " 77%|███████▋  | 547/706 [05:04<01:27,  1.82it/s]\u001b[A\n",
            " 78%|███████▊  | 548/706 [05:04<01:38,  1.61it/s]\u001b[A\n",
            " 78%|███████▊  | 549/706 [05:05<01:32,  1.69it/s]\u001b[A\n",
            " 78%|███████▊  | 550/706 [05:06<01:30,  1.73it/s]\u001b[A\n",
            " 78%|███████▊  | 551/706 [05:06<01:27,  1.77it/s]\u001b[A\n",
            " 78%|███████▊  | 552/706 [05:07<01:36,  1.60it/s]\u001b[A\n",
            " 78%|███████▊  | 553/706 [05:07<01:35,  1.60it/s]\u001b[A\n",
            " 78%|███████▊  | 554/706 [05:08<01:32,  1.64it/s]\u001b[A\n",
            " 79%|███████▊  | 555/706 [05:09<01:29,  1.69it/s]\u001b[A\n",
            " 79%|███████▉  | 556/706 [05:09<01:26,  1.74it/s]\u001b[A\n",
            " 79%|███████▉  | 557/706 [05:10<01:24,  1.77it/s]\u001b[A\n",
            " 79%|███████▉  | 558/706 [05:10<01:22,  1.80it/s]\u001b[A\n",
            " 79%|███████▉  | 559/706 [05:11<01:30,  1.62it/s]\u001b[A\n",
            " 79%|███████▉  | 560/706 [05:11<01:26,  1.70it/s]\u001b[A\n",
            " 79%|███████▉  | 561/706 [05:12<01:22,  1.75it/s]\u001b[A\n",
            " 80%|███████▉  | 562/706 [05:13<01:21,  1.78it/s]\u001b[A\n",
            " 80%|███████▉  | 563/706 [05:13<01:30,  1.58it/s]\u001b[A\n",
            " 80%|███████▉  | 564/706 [05:14<01:25,  1.66it/s]\u001b[A\n",
            " 80%|████████  | 565/706 [05:14<01:22,  1.72it/s]\u001b[A\n",
            " 80%|████████  | 566/706 [05:15<01:19,  1.77it/s]\u001b[A\n",
            " 80%|████████  | 567/706 [05:15<01:16,  1.81it/s]\u001b[A\n",
            " 80%|████████  | 568/706 [05:16<01:25,  1.62it/s]\u001b[A\n",
            " 81%|████████  | 569/706 [05:17<01:20,  1.70it/s]\u001b[A\n",
            " 81%|████████  | 570/706 [05:17<01:18,  1.73it/s]\u001b[A\n",
            " 81%|████████  | 571/706 [05:18<01:43,  1.30it/s]\u001b[A\n",
            " 81%|████████  | 572/706 [05:19<01:34,  1.42it/s]\u001b[A\n",
            " 81%|████████  | 573/706 [05:20<01:32,  1.43it/s]\u001b[A\n",
            " 81%|████████▏ | 574/706 [05:20<01:33,  1.41it/s]\u001b[A\n",
            " 81%|████████▏ | 575/706 [05:21<01:33,  1.40it/s]\u001b[A\n",
            " 82%|████████▏ | 576/706 [05:22<01:27,  1.49it/s]\u001b[A\n",
            " 82%|████████▏ | 577/706 [05:22<01:20,  1.60it/s]\u001b[A\n",
            " 82%|████████▏ | 578/706 [05:23<01:16,  1.68it/s]\u001b[A\n",
            " 82%|████████▏ | 579/706 [05:23<01:13,  1.72it/s]\u001b[A\n",
            " 82%|████████▏ | 580/706 [05:24<01:11,  1.77it/s]\u001b[A\n",
            " 82%|████████▏ | 581/706 [05:24<01:10,  1.77it/s]\u001b[A\n",
            " 82%|████████▏ | 582/706 [05:25<01:16,  1.62it/s]\u001b[A\n",
            " 83%|████████▎ | 583/706 [05:26<01:13,  1.67it/s]\u001b[A\n",
            " 83%|████████▎ | 584/706 [05:26<01:10,  1.73it/s]\u001b[A\n",
            " 83%|████████▎ | 585/706 [05:27<01:08,  1.77it/s]\u001b[A\n",
            " 83%|████████▎ | 586/706 [05:27<01:06,  1.80it/s]\u001b[A\n",
            " 83%|████████▎ | 587/706 [05:28<01:05,  1.82it/s]\u001b[A\n",
            " 83%|████████▎ | 588/706 [05:28<01:04,  1.83it/s]\u001b[A\n",
            " 83%|████████▎ | 589/706 [05:29<01:04,  1.82it/s]\u001b[A\n",
            " 84%|████████▎ | 590/706 [05:30<01:03,  1.83it/s]\u001b[A\n",
            " 84%|████████▎ | 591/706 [05:30<01:02,  1.84it/s]\u001b[A\n",
            " 84%|████████▍ | 592/706 [05:31<01:08,  1.65it/s]\u001b[A\n",
            " 84%|████████▍ | 593/706 [05:32<01:13,  1.55it/s]\u001b[A\n",
            " 84%|████████▍ | 594/706 [05:32<01:08,  1.62it/s]\u001b[A\n",
            " 84%|████████▍ | 595/706 [05:33<01:05,  1.69it/s]\u001b[A\n",
            " 84%|████████▍ | 596/706 [05:33<01:03,  1.73it/s]\u001b[A\n",
            " 85%|████████▍ | 597/706 [05:34<01:08,  1.59it/s]\u001b[A\n",
            " 85%|████████▍ | 598/706 [05:35<01:12,  1.48it/s]\u001b[A\n",
            " 85%|████████▍ | 599/706 [05:35<01:07,  1.58it/s]\u001b[A\n",
            " 85%|████████▍ | 600/706 [05:36<01:04,  1.65it/s]\u001b[A\n",
            " 85%|████████▌ | 601/706 [05:36<01:03,  1.66it/s]\u001b[A\n",
            " 85%|████████▌ | 602/706 [05:37<01:00,  1.71it/s]\u001b[A\n",
            " 85%|████████▌ | 603/706 [05:38<01:06,  1.54it/s]\u001b[A\n",
            " 86%|████████▌ | 604/706 [05:38<01:01,  1.66it/s]\u001b[A\n",
            " 86%|████████▌ | 605/706 [05:39<01:13,  1.38it/s]\u001b[A\n",
            " 86%|████████▌ | 606/706 [05:40<01:07,  1.49it/s]\u001b[A\n",
            " 86%|████████▌ | 607/706 [05:40<01:03,  1.55it/s]\u001b[A\n",
            " 86%|████████▌ | 608/706 [05:41<01:00,  1.63it/s]\u001b[A\n",
            " 86%|████████▋ | 609/706 [05:41<00:57,  1.70it/s]\u001b[A\n",
            " 86%|████████▋ | 610/706 [05:42<00:55,  1.73it/s]\u001b[A\n",
            " 87%|████████▋ | 611/706 [05:43<00:59,  1.60it/s]\u001b[A\n",
            " 87%|████████▋ | 612/706 [05:43<00:55,  1.68it/s]\u001b[A\n",
            " 87%|████████▋ | 613/706 [05:44<00:53,  1.73it/s]\u001b[A\n",
            " 87%|████████▋ | 614/706 [05:44<00:52,  1.75it/s]\u001b[A\n",
            " 87%|████████▋ | 615/706 [05:45<00:50,  1.82it/s]\u001b[A\n",
            " 87%|████████▋ | 616/706 [05:45<00:49,  1.83it/s]\u001b[A\n",
            " 87%|████████▋ | 617/706 [05:46<00:50,  1.75it/s]\u001b[A\n",
            " 88%|████████▊ | 618/706 [05:47<00:49,  1.79it/s]\u001b[A\n",
            " 88%|████████▊ | 619/706 [05:47<00:50,  1.71it/s]\u001b[A\n",
            " 88%|████████▊ | 620/706 [05:48<00:48,  1.77it/s]\u001b[A\n",
            " 88%|████████▊ | 621/706 [05:48<00:47,  1.80it/s]\u001b[A\n",
            " 88%|████████▊ | 622/706 [05:49<00:47,  1.78it/s]\u001b[A\n",
            " 88%|████████▊ | 623/706 [05:50<01:01,  1.35it/s]\u001b[A\n",
            " 88%|████████▊ | 624/706 [05:50<00:55,  1.48it/s]\u001b[A\n",
            " 89%|████████▊ | 625/706 [05:51<00:51,  1.57it/s]\u001b[A\n",
            " 89%|████████▊ | 626/706 [05:52<00:54,  1.48it/s]\u001b[A\n",
            " 89%|████████▉ | 627/706 [05:52<00:50,  1.56it/s]\u001b[A\n",
            " 89%|████████▉ | 628/706 [05:53<00:50,  1.56it/s]\u001b[A\n",
            " 89%|████████▉ | 629/706 [05:54<00:47,  1.63it/s]\u001b[A\n",
            " 89%|████████▉ | 630/706 [05:54<00:45,  1.68it/s]\u001b[A\n",
            " 89%|████████▉ | 631/706 [05:55<00:43,  1.72it/s]\u001b[A\n",
            " 90%|████████▉ | 632/706 [05:55<00:41,  1.77it/s]\u001b[A\n",
            " 90%|████████▉ | 633/706 [05:56<00:40,  1.79it/s]\u001b[A\n",
            " 90%|████████▉ | 634/706 [05:56<00:44,  1.63it/s]\u001b[A\n",
            " 90%|████████▉ | 635/706 [05:57<00:46,  1.52it/s]\u001b[A\n",
            " 90%|█████████ | 636/706 [05:58<00:43,  1.62it/s]\u001b[A\n",
            " 90%|█████████ | 637/706 [05:59<00:45,  1.51it/s]\u001b[A\n",
            " 90%|█████████ | 638/706 [05:59<00:43,  1.58it/s]\u001b[A\n",
            " 91%|█████████ | 639/706 [06:00<00:41,  1.63it/s]\u001b[A\n",
            " 91%|█████████ | 640/706 [06:00<00:42,  1.55it/s]\u001b[A\n",
            " 91%|█████████ | 641/706 [06:01<00:40,  1.62it/s]\u001b[A\n",
            " 91%|█████████ | 642/706 [06:01<00:38,  1.68it/s]\u001b[A\n",
            " 91%|█████████ | 643/706 [06:02<00:36,  1.74it/s]\u001b[A\n",
            " 91%|█████████ | 644/706 [06:03<00:34,  1.78it/s]\u001b[A\n",
            " 91%|█████████▏| 645/706 [06:03<00:33,  1.80it/s]\u001b[A\n",
            " 92%|█████████▏| 646/706 [06:04<00:33,  1.80it/s]\u001b[A\n",
            " 92%|█████████▏| 647/706 [06:04<00:32,  1.82it/s]\u001b[A\n",
            " 92%|█████████▏| 648/706 [06:05<00:31,  1.84it/s]\u001b[A\n",
            " 92%|█████████▏| 649/706 [06:05<00:35,  1.62it/s]\u001b[A\n",
            " 92%|█████████▏| 650/706 [06:06<00:36,  1.54it/s]\u001b[A\n",
            " 92%|█████████▏| 651/706 [06:07<00:33,  1.62it/s]\u001b[A\n",
            " 92%|█████████▏| 652/706 [06:07<00:31,  1.70it/s]\u001b[A\n",
            " 92%|█████████▏| 653/706 [06:08<00:32,  1.65it/s]\u001b[A\n",
            " 93%|█████████▎| 654/706 [06:08<00:30,  1.70it/s]\u001b[A\n",
            " 93%|█████████▎| 655/706 [06:09<00:32,  1.57it/s]\u001b[A\n",
            " 93%|█████████▎| 656/706 [06:10<00:29,  1.67it/s]\u001b[A\n",
            " 93%|█████████▎| 657/706 [06:10<00:28,  1.73it/s]\u001b[A\n",
            " 93%|█████████▎| 658/706 [06:11<00:31,  1.53it/s]\u001b[A\n",
            " 93%|█████████▎| 659/706 [06:12<00:29,  1.58it/s]\u001b[A\n",
            " 93%|█████████▎| 660/706 [06:12<00:27,  1.64it/s]\u001b[A\n",
            " 94%|█████████▎| 661/706 [06:13<00:26,  1.71it/s]\u001b[A\n",
            " 94%|█████████▍| 662/706 [06:13<00:24,  1.76it/s]\u001b[A\n",
            " 94%|█████████▍| 663/706 [06:14<00:24,  1.77it/s]\u001b[A\n",
            " 94%|█████████▍| 664/706 [06:16<00:49,  1.18s/it]\u001b[A\n",
            " 94%|█████████▍| 665/706 [06:17<00:40,  1.01it/s]\u001b[A\n",
            " 94%|█████████▍| 666/706 [06:18<00:36,  1.09it/s]\u001b[A\n",
            " 94%|█████████▍| 667/706 [06:18<00:31,  1.25it/s]\u001b[A\n",
            " 95%|█████████▍| 668/706 [06:19<00:27,  1.38it/s]\u001b[A\n",
            " 95%|█████████▍| 669/706 [06:20<00:28,  1.32it/s]\u001b[A\n",
            " 95%|█████████▍| 670/706 [06:20<00:24,  1.45it/s]\u001b[A\n",
            " 95%|█████████▌| 671/706 [06:21<00:22,  1.54it/s]\u001b[A\n",
            " 95%|█████████▌| 672/706 [06:21<00:20,  1.63it/s]\u001b[A\n",
            " 95%|█████████▌| 673/706 [06:22<00:19,  1.68it/s]\u001b[A\n",
            " 95%|█████████▌| 674/706 [06:22<00:19,  1.66it/s]\u001b[A\n",
            " 96%|█████████▌| 675/706 [06:23<00:18,  1.72it/s]\u001b[A\n",
            " 96%|█████████▌| 676/706 [06:23<00:16,  1.77it/s]\u001b[A\n",
            " 96%|█████████▌| 677/706 [06:24<00:16,  1.79it/s]\u001b[A\n",
            " 96%|█████████▌| 678/706 [06:25<00:15,  1.80it/s]\u001b[A\n",
            " 96%|█████████▌| 679/706 [06:25<00:15,  1.79it/s]\u001b[A\n",
            " 96%|█████████▋| 680/706 [06:26<00:17,  1.49it/s]\u001b[A\n",
            " 96%|█████████▋| 681/706 [06:27<00:15,  1.61it/s]\u001b[A\n",
            " 97%|█████████▋| 682/706 [06:27<00:14,  1.68it/s]\u001b[A\n",
            " 97%|█████████▋| 683/706 [06:28<00:13,  1.73it/s]\u001b[A\n",
            " 97%|█████████▋| 684/706 [06:28<00:12,  1.77it/s]\u001b[A\n",
            " 97%|█████████▋| 685/706 [06:29<00:11,  1.78it/s]\u001b[A\n",
            " 97%|█████████▋| 686/706 [06:29<00:11,  1.81it/s]\u001b[A\n",
            " 97%|█████████▋| 687/706 [06:30<00:10,  1.80it/s]\u001b[A\n",
            " 97%|█████████▋| 688/706 [06:31<00:11,  1.62it/s]\u001b[A\n",
            " 98%|█████████▊| 689/706 [06:31<00:10,  1.67it/s]\u001b[A\n",
            " 98%|█████████▊| 690/706 [06:32<00:09,  1.72it/s]\u001b[A\n",
            " 98%|█████████▊| 691/706 [06:32<00:08,  1.75it/s]\u001b[A\n",
            " 98%|█████████▊| 692/706 [06:33<00:07,  1.75it/s]\u001b[A\n",
            " 98%|█████████▊| 693/706 [06:33<00:07,  1.77it/s]\u001b[A\n",
            " 98%|█████████▊| 694/706 [06:34<00:06,  1.80it/s]\u001b[A\n",
            " 98%|█████████▊| 695/706 [06:34<00:06,  1.82it/s]\u001b[A\n",
            " 99%|█████████▊| 696/706 [06:35<00:05,  1.79it/s]\u001b[A\n",
            " 99%|█████████▊| 697/706 [06:36<00:05,  1.61it/s]\u001b[A\n",
            " 99%|█████████▉| 698/706 [06:36<00:04,  1.66it/s]\u001b[A\n",
            " 99%|█████████▉| 699/706 [06:37<00:04,  1.70it/s]\u001b[A\n",
            " 99%|█████████▉| 700/706 [06:37<00:03,  1.72it/s]\u001b[A\n",
            " 99%|█████████▉| 701/706 [06:39<00:03,  1.31it/s]\u001b[A\n",
            " 99%|█████████▉| 702/706 [06:39<00:03,  1.33it/s]\u001b[A\n",
            "100%|█████████▉| 703/706 [06:41<00:02,  1.12it/s]\u001b[A\n",
            "100%|█████████▉| 704/706 [06:41<00:01,  1.23it/s]\u001b[A\n",
            "100%|█████████▉| 705/706 [06:42<00:00,  1.25it/s]\u001b[A\n",
            "100%|██████████| 706/706 [06:43<00:00,  1.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GTLzOD3wwIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/content/best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfA2oXf-8G2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ro_wFnd8Wj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classs = np.argmax(prediction, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOI-0Lo_wwIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv(\"/content/drive/My Drive/Machine _Hack/janta-hack-CV/sample_submission_yxjOnvz.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNcOvg-RwwI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample['emergency_or_not'] = classs\n",
        "sample.to_csv(\"Final_sub_vgg\"+'.csv', header=True, index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax9DFckgma3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l9GIUNvma1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXC8X1Cpmau7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgmd4lz8mas3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4xelGxtmamZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}